{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":"<p>NOTE: Our login instructions have recently changed. We will now be requiring Duo Multi-Factor Authentication (MFA) for login to LCRC clusters. Please follow our updated instructions below.</p>"},{"location":"#getting-started-in-lcrc","title":"Getting Started in LCRC","text":"<p>If you are looking to get access to LCRC for the first time, see below for either Argonne Employees or Non-Employees/Outside Collaborators. If you need to extend or reactivate your Argonne Collaborator account or if your Argonne username has changed, please find information below as well. To access LCRC resources, you need to complete 4 tasks at a minimum:</p> <ol> <li>Get an Argonne Domain or Collaborator Account</li> <li>Join an LCRC Project</li> <li>Enroll in Duo MFA</li> <li>Set Up an SSH Connection</li> </ol> <p>Until ALL of these steps are completed, you will not be able to login to LCRC resources.</p> <p>Once you have setup your account, you should be able to access the resource of your choice by following our system documentation.</p> <p>If you have any questions related to your Argonne account or Argonne Collaborator account status or if you need a password reset, please send email to help@anl.gov or call the Argonne Service Desk at (630) 252-9999. LCRC support staff does not have access to this information directly.</p>"},{"location":"account-project-management/accounts-and-access/","title":"Accounts and Access","text":""},{"location":"account-project-management/accounts-and-access/#for-current-argonne-employees","title":"For Current Argonne Employees","text":"<ol> <li> <p>Existing Argonne Domain Account</p> <ul> <li>If you have an active badge, you likely have an account. It's the same account used for Argonne email and other apps.</li> <li>If you don't have an account or forgot your credentials, contact help@anl.gov or call the Argonne Service Desk at (630) 252-9999.</li> <li>LCRC support cannot directly address issues with your Argonne account.</li> </ul> </li> <li> <p>Joining the LCRC Project:</p> <ul> <li>Go to https://accounts.lcrc.anl.gov and log in with your Argonne credentials.</li> <li>Select Join Project on the left side.</li> <li>Search for the lcrc project and request membership.</li> <li>Instant membership for Argonne employees.</li> <li>You'll receive an email confirming LCRC access.</li> </ul> </li> <li> <p>Final Steps and Cluster Access:</p> <ul> <li>Configure Duo MFA (Instructions).</li> <li>Add a public SSH key (Instructions).</li> <li>Once Duo is setup and the SSH key is added, you can log in to the LCRC clusters.</li> </ul> </li> </ol>"},{"location":"account-project-management/accounts-and-access/#for-non-employeesoutside-collaborators","title":"For Non-Employees/Outside Collaborators","text":"<ol> <li> <p>Argonne Collaborator Account:</p> <ul> <li>Apply at https://apps.anl.gov/registration/collaborators.</li> <li>Requires official Argonne email address of your sponsor (must be an Argonne employee).</li> <li>Accounts are annual and renewable.</li> <li>Non-US citizens may experience a waiting period before approval.</li> <li>Upon approval, you'll receive an email notification.</li> <li>Sponsors can check account status at Cyber Gate Pass.</li> </ul> </li> <li> <p>Joining a sub-project of LCRC:</p> <ul> <li>Join an existing LCRC project.</li> <li>Log in at https://accounts.lcrc.anl.gov using your Argonne Collaborator credentials.</li> <li>Click Join Project and search for the project indicated by your Argonne Sponsor/PI.</li> <li>Request membership and await approval from your sponsor or the project owner.</li> <li>Upon approval, you'll be added to the LCRC project and receive a home directory on the LCRC clusters.</li> </ul> </li> <li> <p>Final Steps and Cluster Access:</p> <ul> <li>Configure Duo MFA (Instructions).</li> <li>Add a public SSH key (Instructions).</li> <li>Once Duo is setup and the SSH key is added, you can log in to the LCRC clusters.</li> </ul> </li> </ol>"},{"location":"account-project-management/accounts-and-access/#managing-argonne-collaborator-accounts","title":"Managing Argonne Collaborator Accounts","text":""},{"location":"account-project-management/accounts-and-access/#extend-or-reactivate-collaborator-accounts","title":"Extend or Reactivate Collaborator Accounts","text":"<p>If an account is set to expire soon:</p> <ul> <li>Users: Contact your Argonne sponsor to request an extension.</li> <li>Argonne Sponsors: Have your division HR representative update the end date in Workday and ensure the job profile is \"Outside Collaborator.\"</li> </ul> <p>If an account has already expired:</p> <ul> <li>Users: Re-register at Argonne Collaborator Registration page using your existing username to retain access to previous data.</li> <li>Argonne Sponsors: Invite the collaborator to re-register via Cyber Gate Pass, and ensure they use their original username for continuity.</li> </ul>"},{"location":"account-project-management/accounts-and-access/#lcrc-access-post-argonne-appointment","title":"LCRC Access Post-Argonne Appointment","text":"<p>Transitioning to an External Collaborator:</p> <ul> <li>Apply for an Argonne Collaborator account using your sponsor's Argonne email address after your appointment ends.</li> <li>You cannot apply while the current Argonne appointment is active.</li> <li>If approved within 90 days of appointment expiration, contact LCRC support with old and new usernames for assistance in continuing LCRC access.</li> </ul>"},{"location":"account-project-management/accounts-and-access/#changes-to-your-argonne-username","title":"Changes to Your Argonne Username","text":"<p>If your Argonne username changes:</p> <ul> <li>Contact LCRC support with both your old and new usernames to update your user information on LCRC's end.</li> </ul>"},{"location":"account-project-management/mfa-yubikey/","title":"Yubikey MFA","text":""},{"location":"account-project-management/mfa-yubikey/#acquiring-a-yubikey-for-mfa","title":"Acquiring a Yubikey for MFA","text":"<p>If you cannot install the Duo Mobile App for MFA to LCRC systems and if approved, you will need to be given a physical Yubikey hardware token. Please contact LCRC Support to begin this process.</p> <p>After you have been given a Yubikey by LCRC staff for MFA either in person or by mail, contact LCRC Support once again. Give them the Serial Number listed on the physical Yubikey hardware token and they will add it to your LCRC account manually. Once added and notified by LCRC staff, you should be able to login to the LCRC Accounts page and LCRC clusters with your Yubikey instead of Duo. All future logins will require your MFA token.</p>"},{"location":"account-project-management/mfa-yubikey/#logging-into-the-lcrc-accounts-page","title":"Logging into the LCRC Accounts Page","text":"<ol> <li> <p>Make sure your physical Yubikey hardware token is plugged into a USB slot on your local computer.</p> </li> <li> <p>Login to https://accounts.lcrc.anl.gov with your Argonne Domain or Argonne Collaborator account username and password. If you have forgotten your password, please call the Argonne Service Desk at +1-630-252-9999.</p> </li> <li> <p>You should be prompted to select a Device. Select Token in the Device dropdown.  </p> </li> <li> <p>Press the Enter a Passcode button. </p> </li> <li> <p>Click on the highlighted text box so it takes input. Do not enter any text. </p> </li> <li> <p>On your physical Yubikey hardware token, press the button for 1 to 2.5 seconds. A random string of text will be entered into the text box and a return character will be sent as well. It should automatically log you in to the accounts page now, you should not have to press the Log In button.</p> </li> </ol>"},{"location":"account-project-management/mfa-yubikey/#logging-into-lcrc-clusters","title":"Logging into LCRC Clusters","text":"<p>Once your Yubikey is working, you can also configure your SSH key to complete our login requirements for MFA into LCRC clusters. Make sure your SSH key is configured and when you SSH to a cluster, you should be prompted to use your token after your SSH key authenticates. The output should look similar to the below:</p> <pre><code>Duo two-factor login for &lt;username&gt;\n\nEnter a passcode or select one of the following options:\n\nPasscode:\n</code></pre> <p>With the Passcode prompt shown, now on your physical Yubikey hardware token, press the button for 1 to 2.5 seconds. A random string of text will be entered into the CLI and a return character will be sent as well. It should automatically log you in to the cluster now.</p> <p>As a reminder, please contact support@lcrc.anl.gov with any issues.</p>"},{"location":"account-project-management/mfa/","title":"Duo MFA","text":""},{"location":"account-project-management/mfa/#enrolling-in-duo-mfa","title":"Enrolling in Duo MFA","text":"<p>After you have joined the lcrc project or a sub-project of LCRC, you will be required to enroll in the CELS Duo MFA system on your next login to the LCRC Accounts System. If you are already logged in, you can logout and log back in to complete the setup right away.</p> <p>Note: If you cannot install the Duo Mobile App in Step 5 below, please first verify that your device OS is up to date. You can also reference the Duo help documentation for a list of compatibile devices and versions. If you still cannot install the Duo Mobile App because your device cannot be updated, is not compatible, or you do not have a Smartphone/Tablet, please contact support@lcrc.anl.gov and we may assign you a Yubikey instead.</p> <ol> <li> <p>Login to https://accounts.lcrc.anl.gov with your Argonne Domain or Argonne Collaborator account username and password. If you have forgotten your password, please call the Argonne Service Desk at +1-630-252-9999.</p> </li> <li> <p>You should be prompted to configure Duo MFA. Select the device type you want to register for Duo. </p> </li> <li> <p>Add your mobile phone number. </p> </li> <li> <p>Select your device OS. We will choose Android in this example. </p> </li> <li> <p>Install the Duo Mobile App. The official Duo documentation has instructions for both iOS and Android devices. Make sure you are downloading the official Duo Mobile App as it may not be the first search in your device's app store. </p> </li> <li> <p>Open the Duo Mobile App, tap the + button, and scan the barcode. </p> </li> <li> <p>Choose your default authentication method. </p> </li> <li> <p>Continue to login and test your newly added device. </p> </li> </ol> <p>As a reminder, please contact support@lcrc.anl.gov with any issues.</p> <p>Once Duo MFA is configured, you can now configure your SSH key to complete our login requirements. All future logins will require your MFA token.</p>"},{"location":"account-project-management/mfa/#add-a-devicesecondary-auth-to-duo","title":"Add a Device/Secondary Auth to Duo","text":"<p>You occasionally may need to change or add a device. Adding multiple methods of authentication is important, so that you're able to add new devices in situations when your original device may be no longer in your possession.</p> <p>To start, visit https://accounts.lcrc.anl.gov and enter your Argonne login credentials on that screen. You will be prompted to initiate a \"Duo Push\" or enter a code. However, on the left side of the screen is another menu, including \"Add a new device\" and \"My Settings &amp; Devices\". Selecting either of those will allow you to add more authentication devices to your account. You will need to authenticate with Duo first before you can make any changes.</p> <p>Note, Duo Federal (our provider for this service) does not allow SMS-based authentication, so adding a second device, if you have one, is a good way to ensure you don't get locked out of your account.</p>"},{"location":"account-project-management/mfa/#device-no-longer-in-your-possession","title":"Device No Longer in Your Possession","text":"<p>If you are unable to login due to no longer possessing your registered device, please contact support@lcrc.anl.gov.</p>"},{"location":"account-project-management/mfa/#setting-duo-push-as-the-default-option","title":"Setting Duo Push as the Default Option","text":"<p>If needed, you can set Duo to Push automatically instead of choosing an authentication method on each login.</p> <p>To do this, visit https://accounts.lcrc.anl.gov and enter your Argonne login credentials on that screen. You will be prompted to initiate a \"Duo Push\" or enter a code. However, on the left side of the screen is another menu. Select \"My Settings &amp; Devices\". You will be prompted to authenticate first with Duo, then you can change the option \"When I login\" from \"Ask me to choose an authentication method\" to \"Automatically send this device a Duo Push\". Make sure to Save before exiting.</p>"},{"location":"account-project-management/project-management/","title":"Managing Projects","text":"<p>This page describes projects in detail, including policies, concepts, background, etc.</p>"},{"location":"account-project-management/project-management/#the-project-life-cycle","title":"The Project Life Cycle","text":"<p>Projects normally go through the following life cycle. Detailed descriptions of the life cycle will be elaborated further down on this page.</p> <ul> <li>The Principal Investigator (PI) requests a project using at https://accounts.lcrc.anl.gov. The PI must be a current Argonne employee.</li> <li>The project request is sent to the LCRC Allocations Administrator and to the LCRC Allocations Committee.</li> <li>The committee's decision is reported via email to the project requester.</li> <li>If the project has been approved, the mail will include the number of hours allocated to the project. This number may be different from what was requested. This number may also be some initial allocation that will subsequently be augmented based on decisions by the LCRC Allocations Committee.</li> <li>As a part of creating the project, someone on the LCRC Allocations Committee will be affiliated with the project as a Point of Contact (PoC). That person will be the project's contact on the committee. They are expected to become moderately familiar with the project, to act as the project's advocate if necessary, and to be able to explain the project and the project's status to the committee.</li> <li>Every fiscal quarter starting October 1, all projects will have their allocations zeroed out and be restarted with new allocations as requested and approved. This will be done in order to adjust and balance the use of the system. Unused time does not carry over to the next quarter.</li> <li>When making quarterly decisions, the Allocations Committee PoC will look at the usage for the previous quarter and may query any projects that have not been using most of their time to learn what their plan is for the next quarter. Sometimes they also query projects that have used a lot of time for their future plans.</li> <li>Once the project has been created, PIs can add other users to the project, appoint Proxies (or Co-PIs), and administer the project's allocation.</li> <li>In advance of the annual October (Argonne's new fiscal year) re-allocation, PIs will be reminded to send in a request for the next year's allocation for their project.</li> <li>Also in advance of the annual October re-allocation, PIs will also be required to provide a report on their project at that time. If reports had been sent in for previous quarters, those will be sufficient, if they are current. The basic goal here is to get at least one annual report for each project. This report will be used to help describe the overall use of the systems and will also be used when deciding on annual allocations for all projects. The format of the report will be roughly 2-3 pages long, with pictures highly encouraged. Projects that do not submit a report will not receive any new time for the new fiscal year until a report is received.</li> <li>LCRC allocations granted each quarter use Argonne's fiscal calendar. Allocations are granted on the first day of the new fiscal quarter at midnight. Quarters are divided into the following time frames:</li> <li>1st Quarter (October 1 \u2013 December 31)</li> <li>2nd Quarter (January 1 \u2013 March 31)</li> <li>3rd Quarter (April 1 \u2013 June 30)</li> <li>4th Quarter (July 1 \u2013 September 30)</li> </ul>"},{"location":"account-project-management/project-management/#example-project-popcorn","title":"Example Project: \"Popcorn\"","text":"<p>Let's explore a sample project to illustrate how the LCRC allocation system functions. The project, named popcorn, aims to simulate Popcorn Kernel Dynamics. It involves a Principal Investigator (PI) and three collaborating scientists.</p>"},{"location":"account-project-management/project-management/#project-life-cycle-initial-allocation","title":"Project Life Cycle &amp; Initial Allocation","text":"<p>After its creation, popcorn would be granted an initial allocation, for instance, 5,000 node-hours for the quarter.</p>"},{"location":"account-project-management/project-management/#usage-scenario","title":"Usage Scenario","text":"<p>Imagine one of the collaborating scientists runs a job that takes 10 hours and utilizes 25, 128-core nodes. This would consume:</p> <ul> <li><code>10 hours (job duration) x 25 nodes = 250 node-hours</code></li> </ul> <p>As a result, 4,750 node-hours would remain from the original allocation.</p>"},{"location":"account-project-management/project-management/#running-out-of-node-hours","title":"Running Out of Node-Hours","text":"<p>Once all 4,750 remaining node-hours are exhausted, the project will be unable to execute additional jobs. At this point, the team would need to consider requesting more computational time.</p>"},{"location":"account-project-management/project-management/#requesting-additional-allocation","title":"Requesting Additional Allocation","text":"<p>The designated PI can formally request additional node-hours for the project. This request will be subject to review and approval by the LCRC Allocations Committee.</p> <ul> <li>Communication: The decision on the request will be emailed to the PI upon completion of the required web form.</li> </ul>"},{"location":"account-project-management/project-management/#additional-resources","title":"Additional Resources","text":"<p>For a practical guide to project allocation requests, refer to the Sample Project Request.</p>"},{"location":"account-project-management/project-management/#project-pis-and-user-accounts","title":"Project PIs and User Accounts","text":"<p>Each project within the LCRC system is managed by at least one Primary Investigator (PI). The PI serves as the main point of contact for matters like resource allocations. In addition, projects can have Proxies (also known as Co-PIs) who share managerial responsibilities with the PI.</p>"},{"location":"account-project-management/project-management/#eligibility-for-pis-and-proxies","title":"Eligibility for PIs and Proxies","text":"<ul> <li>Primary Investigator (PI): Must be permanent Argonne staff or Argonne associates.</li> <li>Proxies (Co-PIs): Also need to be permanent Argonne staff or Argonne associates.</li> </ul> <p>Resident associates, Joint Appointments, Visiting faculty/students/intern should have their ANL supervisors be the PIs for their projects.</p>"},{"location":"account-project-management/project-management/#user-account-association","title":"User Account Association","text":"<p>A project can have various levels of user involvement:</p> <ul> <li>Single User: Some projects might only have one user account, which is the PI.</li> <li>Multiple Users: Other projects could involve multiple user accounts, possibly even dozens.</li> </ul> <p>A single user account can be associated with multiple projects and can also serve as the PI for multiple projects.</p>"},{"location":"account-project-management/project-management/#roles-and-responsibilities","title":"Roles and Responsibilities","text":""},{"location":"account-project-management/project-management/#pi-responsibilities","title":"PI Responsibilities","text":"<ol> <li>User Management: The PI is in charge of adding and removing user accounts linked to the project.</li> <li>Allocation Management: The PI administers the node-hour allocations for the project, outlining who among the project members is authorized to use what portion of the allocated resources.</li> </ol>"},{"location":"account-project-management/project-management/#summary","title":"Summary","text":"<p>In a nutshell, the PI and any Proxies are responsible for both user and resource management within their projects. They are the go-to contacts for allocation decisions and administrative tasks.</p>"},{"location":"account-project-management/project-management/#requesting-a-new-lcrc-project","title":"Requesting a New LCRC Project","text":""},{"location":"account-project-management/project-management/#who-can-request","title":"Who Can Request?","text":"<p>Only Argonne employees are eligible to initiate a new project within the LCRC.</p>"},{"location":"account-project-management/project-management/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>1. Log In:</p> <ul> <li>Visit the LCRC Accounts page.</li> <li>Use your Argonne credentials to log in.</li> </ul> <p>2. Access the Request Link:</p> <ul> <li>Locate and click on the Request New LCRC Project option in the left-hand sidebar.</li> </ul> <p></p> <p>Note: If the link isn't visible, join the lcrc project. Follow this guide for assistance.</p> <p>3. Complete the Form:</p> <ul> <li>Provide the necessary details in the required fields.</li> <li>Click the Request project button upon completion.</li> </ul> <p>4. Approval Process:</p> <ul> <li>Your project request will undergo a review cycle.</li> <li>Await an email notification regarding the approval decision.</li> </ul> <p>5. Post-Approval Actions:</p> <p>Once approved and the project is set up, you can:</p> <ul> <li>Add or remove users and Proxies (Co-PIs).</li> <li>Request additional allocations.</li> <li>Edit project information.</li> </ul> <p>Your project will have a corresponding Unix group with the same name for member access.</p> <p>6. Storage Requests:</p> <p>For storage requests exceeding 1TB, provide a justification.</p>"},{"location":"account-project-management/project-management/#join-an-existing-lcrc-project","title":"Join an Existing LCRC Project","text":""},{"location":"account-project-management/project-management/#who-can-join","title":"Who Can Join?","text":"<p>Anyone with a new or existing Argonne account can request to join an existing project.</p> <p>If you are an Argonne employee, you should first join the lcrc project. However, if you are a collaborator, you will need to join a sub-project of LCRC.</p>"},{"location":"account-project-management/project-management/#steps-to-join-a-project","title":"Steps to Join a Project","text":"<p>1. Contact the Project PI:</p> <p>For collaborators, if you already know the project PI within LCRC that you wish to join, contact them directly and request them to add you to the project.</p> <p>2. Self-Initiate Membership:</p> <p>If you'd like to send a request to the project PI:</p> <p>a. Access LCRC Accounts:</p> <ul> <li>Visit the LCRC Accounts page.</li> <li>Log in using your Argonne credentials.</li> </ul> <p>b. Locate Join Project:</p> <ul> <li>Click on the Join Project option on the left sidebar.</li> </ul> <p></p> <p>c. Search for the Project:</p> <ul> <li>Enter the name of the project you wish to join in the search box.</li> </ul> <p></p> <ul> <li>The list will update to display projects matching your search term.</li> </ul> <p>d. Request Membership:</p> <ul> <li>Click on the desired project name from the list.</li> <li>Then click on the Request Membership button.</li> </ul> <p></p> <p>3. Approval:</p> <p>After the project owner approves your membership request, you'll have access to use the project hours for your tasks.</p>"},{"location":"account-project-management/project-management/#managing-your-lcrc-project","title":"Managing Your LCRC Project","text":"<p>If you hold the role of a Project Owner (PI) or a Proxy (Co-PI), you're empowered to manage and tailor your LCRC project. Follow this structured guide:</p> <p>1. Access the LCRC Account Page:</p> <ul> <li>Visit the LCRC Accounts page.</li> <li>Sign in with your Argonne credentials.</li> </ul> <p>2. Find Your Project:</p> <ul> <li>Go to Projects &gt; Owned on the left sidebar.</li> <li>Select the project you'd like to oversee.</li> </ul> <p>3. Project Management Options:</p> <p>Within the project management dashboard, you can:</p> <ul> <li>Add or remove project members.</li> <li>Handle pending membership requests.</li> <li>Designate or exclude Proxies (Co-PIs).</li> <li>Seek more project allocations or storage.</li> <li>Update project information.</li> </ul> <p>4. Save Your Adjustments:</p> <ul> <li>Remember to hit the Save Project info button post-modifications.</li> </ul> <p>For support or inquiries, email support@lcrc.anl.gov.</p>"},{"location":"account-project-management/ssh/","title":"Logging In and SSH Keys","text":"<p>LCRC only supports OpenSSH-based clients and does not support PuTTY.</p> <p>After you have configured Duo MFA for LCRC, you can continue to creating an SSH keypair. You will need BOTH Duo MFA and an SSH keypair configured to login to LCRC resources.</p>"},{"location":"account-project-management/ssh/#creating-ssh-keys","title":"Creating SSH Keys","text":"<p>Generate a pair of SSH keys with the ssh-keygen command; in this example we create an ed25519 key.</p> <pre><code>$ ssh-keygen -a 100 -t ed25519\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/Users/USER/.ssh/id_ed25519):\n</code></pre> <p>You can change the name of the ssh key here, which is useful if you have several keys. Make note of the name if you use a different one other than the default.  We will presume you went with the defaults here.</p> <p>Note: If you choose a different name you will need to specify the key to use in the ssh config file or in the ssh command itself.</p> <pre><code>Enter passphrase (empty for no passphrase):\n</code></pre> <p>A strong passphrase is required!</p> <pre><code>Enter same passphrase again:\n</code></pre> <p>Repeat the strong passphrase.</p> <pre><code>Your identification has been saved in /Users/USER/.ssh/id_ed25519.\n</code></pre> <p>(<code>id_ed25519</code> is your private key. Keep it secure, do not share it, and be cognizant of where you store it.)</p> <pre><code>Your public key has been saved in /Users/USER/.ssh/id_ed25519.pub.\nThe key fingerprint is:\nSHA256:lSglfiIzcdJumCtz1RI03sulFJ3pA3hZcFMbPPEY14Y USER@foo\n</code></pre> <p>This is your public key.</p>"},{"location":"account-project-management/ssh/#adding-your-public-key-to-your-account","title":"Adding Your Public Key to Your Account","text":"<p>After you generate your SSH key pair, add ONLY the public key to your account at https://accounts.lcrc.anl.gov.</p> <ul> <li>Copy the contents of the .pub file generated above (in the example above, <code>~/.ssh/id_ed25519.pub</code>)</li> <li>Choose \u201cAdd Key\u201d at the bottom of the Account Information page after login.</li> <li>Paste what you copied into the \u201cKey\u201d section that appears.  The \u201cDescription\u201d is purely informational and allows you to give it a meaningful or memorable name/description for future reference.</li> </ul>"},{"location":"account-project-management/ssh/#logging-in","title":"Logging In","text":"<p>Due to updated security requirements, direct SSH access to LCRC login nodes is no longer permitted. All inbound access must now go through the CELS login nodes using a jump host configuration.</p> <p>You cannot SSH directly into the CELS login nodes. Instead, connect using the command below (replacing <code>&lt;username&gt;</code> and <code>&lt;ssh_private_key&gt;</code> accordingly):</p>"},{"location":"account-project-management/ssh/#basic-configuration","title":"Basic Configuration","text":"<p>We\u2019ve added an LCRC alias to the CELS login nodes for this as well. Using Improv as an example, a connection would look like:</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov\n</code></pre>"},{"location":"account-project-management/ssh/#setting-up-ssh-config","title":"Setting Up SSH Config","text":"<p>Alternatively, you can add something like the following to your .ssh/config file:</p> <pre><code>Host logins.lcrc.anl.gov\n  HostName logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost bebop.lcrc.anl.gov bebop\n  HostName bebop.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost improv.lcrc.anl.gov improv\n  HostName improv.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost crossover.lcrc.anl.gov crossover\n  HostName crossover.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost chrysalis.lcrc.anl.gov chrysalis\n  HostName chrysalis.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost swing.lcrc.anl.gov swing\n  HostName swing.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n</code></pre> <p>If you add the above to your SSH config file, you can do the following, using Improv as an example:</p> <pre><code>ssh improv.lcrc.anl.gov\n</code></pre> <p>or</p> <pre><code>ssh improv\n</code></pre> <p>Regardless of how you decide to SSH into LCRC, with Duo MFA also configured, you will see a Duo prompt during your SSH connection:</p> <pre><code>Duo two-factor login for &lt;username&gt;\n\nEnter a passcode or select one of the following options:\n\n 1. Duo Push to XXX-XXX-1234\n\nPasscode or option (1-1): 1\nSuccess. Logging you in...\n</code></pre> <p>Assuming you have only configured one device, type in the number 1 on the 'Passcode or option' line like above and press Enter to choose your configured mobile device and Accept the Duo push on that mobile device. You should now be logged into the desired cluster.</p>"},{"location":"account-project-management/ssh/#using-gui-applications-over-ssh","title":"Using GUI Applications Over SSH","text":"<p>For GUI applications over SSH, enable X11 forwarding:</p> <p>Command line:</p> <pre><code>ssh -X -o ProxyCommand=\"ssh -q -W %h:%p -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov\n</code></pre> <p>Or in your config file:</p> <pre><code>Host improv.lcrc.anl.gov improv\n  HostName improv.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n  ForwardX11 yes\n</code></pre> <p>Then connect as usual:</p> <pre><code>ssh improv\n</code></pre> <p>You can apply these same methods to other clusters.</p>"},{"location":"account-project-management/ssh/#windows-users","title":"Windows Users","text":"<p>Windows 10/11 users connecting to LCRC via Command Prompt, PowerShell, or Visual Studio Code\u2019s SSH extension may encounter errors such as \u201cCorrupted MAC on input\u201d or \u201cmessage authentication code incorrect.\u201d This results from an outdated OpenSSL library in Windows.</p> <p>If you see this error, a simple workaround is to specify a supported MAC algorithm in your SSH command:</p> <pre><code>ssh -m hmac-sha2-512 -o ProxyCommand=\"ssh -q -W %h:%p -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov \n</code></pre>"},{"location":"account-project-management/ssh/#setting-up-ssh-config-on-windows-command-prompt","title":"Setting Up SSH Config on Windows (Command Prompt)","text":"<p>1. Create the .ssh directory (if it doesn't exist):</p> <p>Open Command Prompt and run:</p> <pre><code>if not exist \"%USERPROFILE%\\.ssh\" md \"%USERPROFILE%\\.ssh\"\n</code></pre> <p>2. Generate the SSH config file with your host entries:</p> <p>Run the following block exactly as shown:</p> <pre><code>(\necho Host *\necho MACs hmac-sha2-512\necho Host logins.lcrc.anl.gov\necho HostName logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\necho Host bebop.lcrc.anl.gov bebop\necho HostName bebop.lcrc.anl.gov\necho ProxyJump logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\necho Host improv.lcrc.anl.gov improv\necho HostName improv.lcrc.anl.gov\necho ProxyJump logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\necho Host crossover.lcrc.anl.gov crossover\necho HostName crossover.lcrc.anl.gov\necho ProxyJump logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\necho Host chrysalis.lcrc.anl.gov chrysalis\necho HostName chrysalis.lcrc.anl.gov\necho ProxyJump logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\necho Host swing.lcrc.anl.gov swing\necho HostName swing.lcrc.anl.gov\necho ProxyJump logins.lcrc.anl.gov\necho User ^&lt;username^&gt;\necho IdentityFile ~/.ssh/^&lt;ssh_private_key^&gt;\n) &gt; \"%USERPROFILE%\\.ssh\\config\"\n</code></pre> <p>3. Edit the SSH config file to insert your actual details:</p> <pre><code>notepad %USERPROFILE%\\.ssh\\config\n</code></pre> <p>Then:</p> <ul> <li>Replace <code>&lt;username&gt;</code> with your actual LCRC username.</li> <li>Replace <code>&lt;ssh_private_key&gt;</code> with the filename of your private key (e.g., id_ed25519).</li> </ul> <p>4. Test the SSH connection:</p> <p>Try:</p> <p><code>ssh improv</code></p> <p>You'll be prompted twice for your SSH key password followed by a Duo prompt.</p>"},{"location":"account-project-management/ssh/#connecting-with-winscp","title":"Connecting with WinSCP","text":"<p>Note: These steps assume you have already set up a functional SSH config file. If not, refer to the previous guide before proceeding.</p> <p>1. Open WinSCP and go to the Site Manager.</p> <p>2. Click Tools (bottom left) and select Import Sites.</p> Click to view screenshot <p></p> <p>3. A list of LCRC cluster entries should appear, pulled directly from your SSH config file.</p> <p>\u2013 Ensure all relevant entries are checked, then click OK.</p> Click to view screenshot <p></p> <p>4. When prompted to convert your OpenSSH private key to PuTTY format, click OK.</p> Click to view screenshot <p></p> <p>5. Enter your private key passphrase when prompted.</p> Click to view screenshot <p></p> <p>6. Save the resulting .ppk (PuTTY Private Key) file to your ~.ssh\\ directory.</p> Click to view screenshot <p></p> <p>7. You should now see the imported LCRC clusters listed in Site Manager.</p> <ul> <li>Select your desired cluster.</li> <li>Leave the password field blank.</li> <li>Click Login to connect.</li> </ul> Click to view screenshot <p></p> <p>8. During the connection, you will be prompted to:</p> <ul> <li>Enter your SSH private key passphrase (you will be asked twice)</li> <li>Complete Duo authentication</li> </ul> Click to view screenshot <p></p>"},{"location":"account-project-management/ssh/#debugging-a-failed-connection","title":"Debugging a Failed Connection","text":"<p>If you encounter login issues, check your internet connection, ensure the correct public key is uploaded, verify your username, hostname, and SSH private key are correct, and check for any misconfigurations in <code>~/.ssh/config</code>.</p> <p>Common Issues:</p> <ul> <li>Client Configuration: Verify the correct permissions for your SSH files.</li> <li>Server Configuration: Ensure your home and .ssh directories have the correct permissions.</li> <li>Maintenance and Login Nodes: Be aware of maintenance periods and check if you're connecting to responsive nodes.</li> <li>Not enrolled in Duo MFA.</li> </ul> <p>Advanced Troubleshooting:</p> <p>If you're still facing issues, provide the output from the following commands to support:</p> <pre><code>ssh -vvv -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov\nls -la ~/.ssh\ncat ~/.ssh/config\n</code></pre>"},{"location":"account-project-management/ssh/#specific-error-messages","title":"Specific Error Messages","text":"<p>There are a several error messages that you may need to look out for.</p> <p>Your account does not have access to this application. Contact an administrator for assistance.</p> <p>You haven't joined the LCRC project or sub-project of LCRC. Please see our documentation on joining a project.</p> <p>Access is not allowed because you are not enrolled in Duo. Please contact your organization's IT help desk.</p> <p>You haven't enrolled in Duo MFA. Please see our documentation on Duo MFA enrollment.</p> <p>Your account is disabled and cannot access this application. Please contact your administrator.</p> <p>You have failed a Duo attempt 3 times in a row. Duo will automatically lock you out for 30 minutes. You may try logging in again after the 30 minutes. If you continue to have lock out failures, please contact LCRC support.</p> <p>Too many authentication failures</p> <p>You have failed an SSH key or Duo credential check and were kicked out to avoid a block in Duo (a Duo block will be issued after 3 failed attempts for 30 minutes and will be cleared automatically). You can try again with the correct SSH key passphrase and Accepting your login attempt from your Duo device.</p> <p>Operation Timed Out</p> <p>You have failed an SSH key or Duo credential check too many times and have been blocked by the Argonne firewall. You will need to send an email to LCRC support with the IP address you are trying to connect from. Please make sure to send your real, public IP and not one from your local network. After we remove the block, please check your SSH and Duo settings to correct the issue before trying your connection again to avoid future blocks.</p>"},{"location":"account-project-management/ssh/#downed-login-nodes","title":"Downed Login Nodes","text":"<p>Occasionally LCRC login nodes may become unresponsive due to a number of various failures unexpectedly. Because of the round-robin nature of the connection, you may land on one of these bad nodes when you try to SSH to LCRC. We'll try to make sure each node is up at all times, but you may attempt to connect to the clusters during this unexpected down time. To test whether or not the problem is on your end or on the LCRC side and if you've already exhausted the other troubleshooting steps, try to connect to a specific login node.</p> <p>To do this, you can substitute your basic SSH command of <code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov</code>, for example, with these instead.</p> <p>For Improv:</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@ilogin1.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@ilogin2.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@ilogin3.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@ilogin4.lcrc.anl.gov\n</code></pre> <p>For Bebop:</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@beboplogin1.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@beboplogin2.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@beboplogin3.lcrc.anl.gov\nssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@beboplogin4.lcrc.anl.gov\n</code></pre> <p>If you try a couple of these nodes and still can't connect, you can continue troubleshooting. Of course in extremely rare cases most of our login nodes can be down so you can always contact us if you've exhausted all of your connection options.</p>"},{"location":"allocation-management/allocations/","title":"Allocations on LCRC Computing Resources","text":""},{"location":"allocation-management/allocations/#overview-of-lcrc-clusters","title":"Overview of LCRC Clusters","text":"<p>The LCRC operates three distinct clusters, all of which measure allocations in node hours. For an overview on our general guidelines on allocation requests and policies, please visit this link.</p>"},{"location":"allocation-management/allocations/#allocations-metrics-for-each-cluster","title":"Allocations Metrics for Each Cluster","text":""},{"location":"allocation-management/allocations/#node-hours","title":"Node Hours","text":""},{"location":"allocation-management/allocations/#improv-and-bebop-clusters","title":"Improv and Bebop Clusters","text":"<p>Allocations on Improv and Bebop are provided (and should be requested) in Node Hours. 1 node on Improv has 128 CPU Cores, and 1 node on Bebop has 36 CPU Cores. When requesting or viewing your allocation(s), please take this into consideration. Balances, transactions and other sbank details displayed from sbank commands will update every 5 minutes.</p> <p><code>Node Hours = Number of Nodes Used \u00d7 Time in Hours</code></p> <ul> <li>Number of Nodes Used: The quantity of compute nodes utilized for the job.</li> <li>Time in Hours: The duration for which these nodes are used.</li> </ul>"},{"location":"allocation-management/allocations/#swing-cluster","title":"Swing Cluster","text":"<p>Allocations on Swing are provided in Node Hours. However, on Swing, 1 Node Hour equates to 8 GPU Hours.</p>"},{"location":"allocation-management/allocations/#allocation-usage-and-tracking","title":"Allocation Usage and Tracking","text":""},{"location":"allocation-management/allocations/#general-policies","title":"General Policies","text":"<ul> <li>System Error: If a system error occurs that causes a program to crash while it is running, a project won\u2019t be charged for that time. (This policy may be amended in the future in order to promote the use of user-based checkpointing.) The scheduler may or may not deduct the time used from the project\u2019s allocation, depending on how the crash took place. If someone thinks their project should be credited time because of a system crash or other system problem, they should send email to support@lcrc.anl.gov to get that time back into the project.</li> <li>Run Continuation:If a project runs out of allocation time during a run, that run will be allowed to continue to completion.</li> <li>Project Suspension: If a project runs out of allocation time, all users on the project will not be able to run any jobs until time is added again. At the present time, no steps will be taken to stop any jobs associated with that project from running and sitting idle in the job queue.</li> <li>Usage Tracking</li> </ul>"},{"location":"allocation-management/allocations/#requesting-additional-project-time","title":"Requesting Additional Project Time","text":""},{"location":"allocation-management/allocations/#when-to-request-additional-time","title":"When to Request Additional Time","text":"<p>Projects that depleted their quarterly allocation before the end of the quarter should use the backfill queue.</p>"},{"location":"allocation-management/allocations/#annual-time-requests-for-projects","title":"Annual Time Requests for Projects","text":"<ul> <li>Existing Projects: Time requests for the upcoming fiscal year can be made from the first week of September until October 1st.</li> <li>New Projects: New projects may request time throughout the year for the remaining quarters.</li> <li>Post-October 1st: After October 1st, existing projects can request time for any quarter, but there may be restrictions on the maximum hours granted.</li> </ul>"},{"location":"allocation-management/allocations/#mid-quarter-allocations","title":"Mid-Quarter Allocations","text":"<p>Projects that have exhausted their initial quarterly allocations should use the backfill queue till the end of the quarter. Allocation requests submitted between the start of the quarter and the end of the 10th week of the quarter will also have to use the backfill queue. They will be considered for full allocation in the next quarter. Allocation requests submitted after the 10th week of a quarter will have to run in the backfill queue in the next quarter as well.</p> <p>All allocation related tickets are reviewed and responded to once a week on Tuesday.</p>"},{"location":"allocation-management/sbank-allocation-accounting-system/","title":"sbank Allocation Accounting System","text":"<p>sbank is the accounting system within LCRC. It tracks project allocations, usage charges, and refunds. sbank allows queries about the balance and expiration of project allocations.</p> <p>The sbank accounting system helps users manage their allocations and usage per job. It gives the PIs the ability to monitor their allocation usage by user, job, and machine. It also allows the user to monitor their usage per allocation and provides insight on how many hours are left on the project.</p>"},{"location":"allocation-management/sbank-allocation-accounting-system/#getting-started-with-sbank","title":"Getting Started with sbank","text":"<p>sbank Example Commands provides a set of example commands on how to use the most common commands.</p>"},{"location":"allocation-management/sbank-allocation-accounting-system/#sbank-man-pages","title":"sbank Man Pages","text":"<p>Use these sbank man pages to get information on how to use the commands.</p> <ul> <li>sbank</li> <li>sbank-detail</li> <li>sbank-detail-allocations</li> <li>sbank-detail-jobs</li> <li>sbank-detail-projects</li> <li>sbank-detail-transactions</li> <li>sbank-detail-users</li> <li>sbank-list</li> <li>sbank-list-allocations</li> <li>sbank-list-jobs</li> <li>sbank-list-projects</li> <li>sbank-list-transactions</li> <li>sbank-list-users</li> </ul>"},{"location":"allocation-management/sbank-allocation-accounting-system/#pbsslurm-conversion-chart","title":"PBS/Slurm Conversion Chart","text":"<p>If you are coming to PBS from Slurm, we have added a basic conversion chart for your general commands and submit scripts that you can reference that provide similar functions.</p> Description PBS Pro Slurm Submit Job qsub [job_script] sbatch [job_script] Query Jobs qstat squeue Delete Job qdel [job_id] scancel [job_id] Hold User Job qhold [job_id] scontrol hold [job_id] Release User Job qrls [job_id] scontrol release [job_id] List Nodes pbsnodes -a scontrol show nodes Description PBS Pro Slurm Submission Directive #PBS #SBATCH Queue/Partition Selection -q [queue_name] -p [queue_name] Number of Nodes -l select=[count] -N [count] Number of CPUs per Node -l ncpus=[count] -ntasks-per-node=[count] Number of GPUs per Node -l ngpus=[count] --gres=gpu:[count] Charge Account -A [project_name] -account=[project_name] Walltime -l walltime=[hh:mm:ss] -time=[hh:mm:ss] Job Name -N [name] -job-name=[name] Standard Out -o [file_name] -o [file_name] Standard Error -e [file_name] -e [file_name] Email Options -m abe -mail-type=[flags] Email Address -M [email_address] -mail-user=[email_address] <p>Useful variables to use in your scripts:</p> Description PBS Pro Slurm Submission Directory $PBS_O_WORKDIR $SLURM_SUBMIT_DIR Submit Host $PBS_O_HOST $SLURM_SUBMIT_HOST Job ID Number $PBS_JOBID $SLURM_JOBID Job Node List $PBS_NODEFILE $SLURM_JOB_NODELIST Job Array Index $PBS_ARRAYID $SLURM_ARRAY_TASK_ID"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/","title":"Manpage for sbank-detail-allocations","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#sbank-detail-allocations-options","title":"sbank-detail-allocations [options] [ ... ] <p>Detail allocation information. </p> <p>NOTE:    1. The list of  arguments are optional.    2. you can also enter  list by using the -a option multiple times.    3. regardless, both are optional, and you can get detail allocation info using the option filters below.","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>filter on event id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>filter on jobid</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>filter on transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width=","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>**Date Parsing Precedence: **</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions), ...</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>also get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-o-get-only-inactive","title":"-O, --get-only-inactive","text":"<p>only inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-award-type-nameaward_type_name","title":"--award-type-name=AWARD_TYPE_NAME","text":"<p>filter on award type name</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-award-categoryaward_category","title":"--award-category=AWARD_CATEGORY","text":"<p>filter on award category</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>filter on Clusterbank reference id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-get-deleted","title":"--get-deleted","text":"<p>also get deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-get-only-deleted","title":"--get-only-deleted","text":"<p>only deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-history-date-rangeend","title":"--history-date-range=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults: </p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-history","title":"--no-history","text":"<p>do not show history information</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-allocations/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-jobs/","title":"sbank-detail-jobs","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-jobs/#sbank-detail-jobs-options","title":"sbank-detail-jobs [options] [  |  ...  | ] <p>Detail job information.  NOTE: </p> <ol> <li>The arguments  or  are NOT REQUIRED;  <li>event_id is the JOB DATABASE ID; </li> <li> is the SCHEDULER CREATED ID, such as Cobalt;  <li> can also be entered using option -j  ;  <li> can also be entered using option -e  ;  <li> can also be entered using option -r  ;  <li>regardless, you can use options or arguments to get detail job information</li>","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-jobs/#options","title":"OPTIONS","text":"<p>--version</p> <p>show program's version number and exit</p> <p>-h, --help</p> <p>show this help message and exit</p> <p>-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID</p> <p>filter on allocation id</p> <p>-e EVENT_ID, --event-id=EVENT_ID</p> <p>filter on event id</p> <p>-f FIELD_INFO, --field-to-display=FIELD_INFO</p> <p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\" <p>-j JOBID, --jobid=JOBID</p> <p>filter on jobid</p> <p>-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY</p> <p>set number of fields to display</p> <p>-p PROJECT, --project=PROJECT</p> <p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p> <p>-r RESOURCE, --resource=RESOURCE</p> <p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p> <p>-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID</p> <p>filter on transaction id</p> <p>-u USER, --user=USER</p> <p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p> <p>-w \"FIELD_INFO\", --field-width</p> <p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\" <p>-E END, --end=END</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>-H, --human-readable</p> <p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p> <p>-S START, --start=START</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;,&lt;=, &lt;, == . Operator Defaults: OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE</p> <p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p> <p>--created=CREATED_TIMESTAMP</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>--debug=DEBUG_LEVEL</p> <p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p> <p>--eligible=ELIGIBLE_TIMESTAMP</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>--get-not-charged</p> <p>only un-charged jobs</p> <p>--history-date-range=END</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>--last-updated=LAST_UPDATED_TIMESTAMP</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'gt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012 <p>--no-commas</p> <p>remove commas from comma separated thousands</p> <p>--no-header</p> <p>do not display the header</p> <p>--no-history</p> <p>do not show history information</p> <p>--no-rows</p> <p>do not display the row data</p> <p>--no-sys-msg</p> <p>do not display system message</p> <p>--no-totals</p> <p>do not display the totals</p> <p>--queued=QUEUED_TIMESTAMP</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: ge, gt, le,\u00a0lt,\u00a0eq or &gt;=, &gt;, &lt;=, &lt;, ==. Operator Defaults: OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/","title":"Manpage for sbank-detail-projects","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#sbank-detail-projects-options","title":"sbank-detail-projects [options] [ ... ] <p>Detail project information. </p> <p>NOTE:    1. The list of  arguments are optional   2. you can also enter  list by using the -p option multiple times   3. regardless, both are optional, and you can get detail project info using the option filters below","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:    - YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-projects/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/","title":"Manpage for sbank-detail-transactions","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#sbank-detail-transactions-options","title":"sbank-detail-transactions [options] [ ... ] <p>Detail transaction information. </p> <p>NOTE:    1. The list of  arguments are optional   2. you can also enter  list by using the -t option multiple times   3. regardless, both are optional, and you can get detail transaction info using the option filters below","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-c-comment","title":"-c, --comment","text":"<p>display comment</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>filter on event id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:] for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>filter on jobid</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>filter on transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width=","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-e-job_end-endjob_end","title":"-E JOB_END, --end=JOB_END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-s-job_start-startjob_start","title":"-S JOB_START, --start=JOB_START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-attransaction_at_timestamp","title":"--at=TRANSACTION_AT_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>filter on Clusterbank reference id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-createdjob_created_timestamp","title":"--created=JOB_CREATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-transactions/#-queuedjob_queued_timestamp","title":"--queued=JOB_QUEUED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry</li> <li>OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/","title":"Manpage for sbank-detail-users","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-users/#sbank-detail-users-options","title":"sbank-detail-users [options] [ ... ] <p>Detail user information. </p> <p>**NOTE: **   1. Use -I to include inactive allocations   2. the list of  arguments are optional   3. you can also enter  list by using the -u option multiple times   4. regardless, both are optional, and you can get detail user info using the option filters below","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-users/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-detail-users/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/","title":"Manpage for sbank-detail","text":""},{"location":"allocation-management/not_in_nav/sbank-detail/#sbank-detail-options","title":"sbank-detail  [options] <p>Detail Meta Command</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-detail/#commands","title":"COMMANDS","text":"<ul> <li>allocations [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT) </li> <li>categories [-f|-n|-w|...] </li> <li>messages [-f|-n|-w|...] </li> <li>names [-f|-n|-w|...] jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...] </li> <li>transactions [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-detail/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-detail/#-a-allocation","title":"-a --allocation","text":"<p>enter allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-c-comment","title":"-c --comment","text":"<p>enter comment for new or edit commands, display comment for list commands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-e-event-id","title":"-e --event-id","text":"<p>enter event db id; event db id is an internal id created by the charging system</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-f-field","title":"-f --field","text":"<p>enter [:], width is optional; enter -f? or -f \"?\" for available fields, + to add fields"},{"location":"allocation-management/not_in_nav/sbank-detail/#-h-help","title":"-h --help","text":"<p>command line help</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-j-jobid","title":"-j --jobid","text":"<p>enter jobid; jobid is created by the scheduler and is not unique</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-n-num-field","title":"-n --num-field","text":"<p>enter number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-p-project","title":"-p --project","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-r-resource","title":"-r --resource","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-s-suballocation","title":"-s --suballocation","text":"<p>enter suballocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-t-transaction","title":"-t --transaction","text":"<p>enter transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-u-user","title":"-u --user","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-w-field-width","title":"-w --field-width","text":"<p>enter the field width as follows: :, enter -w? or -w \"?\" for available fields"},{"location":"allocation-management/not_in_nav/sbank-detail/#-e-end","title":"-E --end","text":"<p>enter end datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-h-human-readable","title":"-H --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-i-get-inactive","title":"-I --get-inactive","text":"<p>include inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-o-get-only-inactive","title":"-O --get-only-inactive","text":"<p>get only inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-s-start","title":"-S --start","text":"<p>enter start datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-t-type","title":"-T --Type","text":"<p>enter type of transaction</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-all-charges","title":"--all-charges","text":"<p>for list allocations | projects | users, only show info with charges</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-at","title":"--at","text":"<p>enter transaction created datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-award-category","title":"--award-category","text":"<p>enter allocation award category</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-award-type-name","title":"--award-type-name","text":"<p>enter allocation award-type name</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-created","title":"--created","text":"<p>enter created datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-debug","title":"--debug","text":"<p>enter debug level</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-get-deleted","title":"--get-deleted","text":"<p>get deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-get-not-charged","title":"--get-not-charged","text":"<p>get jobs that have not been charged</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-get-only-deleted","title":"--get-only-deleted","text":"<p>get only deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-history-date-range","title":"--history-date-range","text":"<p>enter history datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-last-updated","title":"--last-updated","text":"<p>enter last updated datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-header","title":"--no-header","text":"<p>do not display header</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-history","title":"--no-history","text":"<p>do not display history information</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-rows","title":"--no-rows","text":"<p>do not display rows</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-no-totals","title":"--no-totals","text":"<p>do not display totals</p>"},{"location":"allocation-management/not_in_nav/sbank-detail/#-queued","title":"--queued","text":"<p>enter queued datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-examples/","title":"sbank Example Commands","text":"<p>Below is a set of helpful commands to help you better manage the projects you have running on LCRC Improv.</p> <p>All transactions displayed are in Node Hours. 1 Improv Node Hour is 128 Core Hours. 1 Bebop Node Hour is 36 Core Hours. Balances and transactions displayed will update every 5 minutes.</p>"},{"location":"allocation-management/not_in_nav/sbank-examples/#view-your-projects-allocations","title":"View your Project\u2019s Allocations","text":"<p>Command: <code>sbank-list-allocations [options]</code></p> <pre><code>$ sbank-list-allocations -p &lt;project_name&gt;\nAllocation  Suballocation  Start       End         Resource  Project  Jobs  Charged  Available Balance\n----------  -------------  ----------  ----------  --------  -------  ----  -------  -----------------\n2           2              2023-10-01  2024-01-01  improv    projectX    17     34.2             9965.8\n116         116            2023-10-01  2024-01-01  improv    projectX     0      0.0              500.0\n\n Totals:\n   Rows: 2\n   Improv:\n     Available Balance: 10465.8 node hours\n     Charged          : 34.2 node hours\n     Jobs             : 17\n</code></pre>"},{"location":"allocation-management/not_in_nav/sbank-examples/#view-your-projects-users","title":"View your Project\u2019s Users","text":"<p>Command: <code>sbank-list-users [options]</code></p> <pre><code>$ sbank-list-users -p &lt;project_name&gt;\n User       Jobs  Charged\n ---------  ----  -------\n user1       57    164.7\n user2       28     29.5\n user3      0      0.0\n\nTotals:\n  Rows: 3\n  Resources: improv\n  Projects: projectX\n  Jobs   : 112\n  Charged: 194.2 node hours\n</code></pre>"},{"location":"allocation-management/not_in_nav/sbank-examples/#view-your-projects-transactions","title":"View your Project\u2019s Transactions","text":"<p>Command: <code>sbank-list-transactions [options]</code></p> <pre><code>$ sbank-list-transactions -p &lt;project_name&gt;\n...\n 1661         improv    projectX  2           2              2023-10-26  user1     CHARGE       0.0  1752.imgt1\n 1662         improv    projectX  2           2              2023-10-26  user1     CHARGE       0.0  1753.imgt1\n 1663         improv    projectX  2           2              2023-10-26  user2     CHARGE       0.0  1754.imgt1\n 1664         improv    projectX  2           2              2023-10-27  user2     CHARGE       0.0  1755.imgt1\n 1665         improv    projectX  2           2              2023-10-27  user1     CHARGE       0.0  1756.imgt1\n\nTotals:\n  Rows: 135\n  Improv:\n    Charges Amount : 229.3 node hours\n    Deposits Amount: 11500.0 node hours\n</code></pre>"},{"location":"allocation-management/not_in_nav/sbank-examples/#list-jobs-run-by-a-user","title":"List Jobs Run by a User","text":"<p>Command: <code>sbank-list-jobs [options]</code></p> <pre><code>$ sbank-list-jobs -u &lt;username&gt;\n...\n1611     1727.imgt1  improv    projectX          2           2              user1  0:00:26       0.1\n 1612     1728.imgt1  improv    projectX          2           2              user1  0:00:28       0.1\n 1613     1729.imgt1  improv    projectX          2           2              user1  0:00:26       0.1\n 1614     1730.imgt1  improv    projectX          2           2              user1  0:00:26       0.1\n\nTotals:\n  Rows: 314\n  Improv:\n    Charged: 61.0 node hours\n</code></pre>"},{"location":"allocation-management/not_in_nav/sbank-examples/#get-detailed-allocation-information","title":"Get Detailed Allocation Information","text":"<p>Command: <code>sbank-detail-allocations [options]</code></p> <pre><code>$ sbank-detail-allocations -p &lt;project_name&gt;\n\n-- Allocation Info:\n* Allocation: 2\n* Suballocation: 2\n* Start: 2023-10-01 05:00:00\n* End: 2024-01-01 05:59:59\n* Resource: improv\n* Project: projectX\n* Jobs: 1,517\n* Charged: 3,001.3\n* Available Balance: 7,076.8\n* Allocation Created: 2023-08-11 06:44:25\n* Award Category: NA\n* Award Type: NA\n* Subname: None\n* Primary: 1\n* Restricted: 0\n* Deposits: 10,078.1\n* Pullbacks: 0.0\n* Sub Deposits: 0.0\n* Sub Withdraws: 0.0\n* Disable Message: None\n* Submanagement Enabled: 0\n* Users: None\n* Comment: None\n* Last Updated: 2023-10-19 14:05:24\n* Allocation History: No updates\n* Suballocation History: No updates\n\n-- Allocation Info:\n* Allocation: 116\n* Suballocation: 116\n* Start: 2023-10-01 05:00:00\n* End: 2024-01-01 05:59:59\n* Resource: improv\n* Project: projectX\n* Jobs: 3\n* Charged: 7.0\n* Available Balance: 496.9\n* Allocation Created: 2023-10-19 04:45:42\n* Award Category: NA\n* Award Type: NA\n* Subname: None\n* Primary: 1\n* Restricted: 0\n* Deposits: 503.9\n* Pullbacks: 0.0\n* Sub Deposits: 0.0\n* Sub Withdraws: 0.0\n* Disable Message: None\n* Submanagement Enabled: 0\n* Users: None\n* Comment: None\n* Last Updated: 2023-10-19 14:50:36\n* Allocation History: No updates\n* Suballocation History: No updates\n\nTotals:\n  Items: 2\n  Improv:\n    Available Balance: 7,573.8 node hours\n    Charged          : 3,008.3 node hours\n    Deposits         : 10,582.0 node hours\n    Jobs             : 1,520\n    Pullbacks        : 0.0 node hours\n    Sub Deposits     : 0.0 node hours\n    Sub Withdraws    : 0.0 node hours\n</code></pre> <p>If you are looking for a specific piece of information from sbank that is not listed above, please contact LCRC Support.</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/","title":"Manpage for sbank-list-allocations","text":""},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#sbank-list-allocations-options","title":"sbank-list-allocations [options]","text":"<p>Generate allocation list report. </p> <p>Notes:  1. Use -I to include inactive allocations 2. enter \"-r all\" to get information for all resources</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-c-comment","title":"-c, --comment","text":"<p>display comment</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>filter on event id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>filter on jobid</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>filter on transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-o-get-only-inactive","title":"-O, --get-only-inactive","text":"<p>only inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-award-type-nameaward_type_name","title":"--award-type-name=AWARD_TYPE_NAME","text":"<p>filter on award-type name</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-award-categoryaward_category","title":"--award-category=AWARD_CATEGORY","text":"<p>filter on award category</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>filter on Clusterbank reference id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-get-deleted","title":"--get-deleted","text":"<p>get deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-get-only-deleted","title":"--get-only-deleted","text":"<p>get only deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list-allocations/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/","title":"Manpage for sbank-list-jobs","text":""},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#sbank-list-jobs-options","title":"sbank-list-jobs [options]","text":"<p>Generate job list report Note: To get information for all resources, enter \"-r all\".</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>filter on event id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>filter on jobid</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>filter on transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-eligibleeligible_timestamp","title":"--eligible=ELIGIBLE_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-get-not-charged","title":"--get-not-charged","text":"<p>get only jobs that have not been charged</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list-jobs/#-queuedqueued_timestamp","title":"--queued=QUEUED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/","title":"Manpage for sbank-list-projects","text":""},{"location":"allocation-management/not_in_nav/sbank-list-projects/#sbank-list-projects-options","title":"sbank-list-projects [options]","text":"<p>Generate project list report. </p> <p>Notes: </p> <ol> <li>Use -I to include inactive allocations</li> <li> <ol> <li>to get information for all resources, enter \"-r all\"</li> </ol> </li> </ol>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\" <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list-projects/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/","title":"Manpage for sbank-list-transactions","text":""},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#sbank-list-transactions-options","title":"sbank-list-transactions [options]","text":"<p>Generate transaction list report. </p> <p>Note: To get information for all resources, enter \"-r all\".</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-c-comment","title":"-c, --comment","text":"<p>display comment</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>filter on event id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>filter on jobid</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>filter on transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-e-job_end-endjob_end","title":"-E JOB_END, --end=JOB_END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-s-job_start-startjob_start","title":"-S JOB_START, --start=JOB_START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-attransaction_at_timestamp","title":"--at=TRANSACTION_AT_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>filter on Clusterbank reference id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-createdjob_created_timestamp","title":"--created=JOB_CREATED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list-transactions/#-queuedjob_queued_timestamp","title":"--queued=JOB_QUEUED_TIMESTAMP","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-users/","title":"Manpage for sbank-list-users","text":""},{"location":"allocation-management/not_in_nav/sbank-list-users/#sbank-list-users-options","title":"sbank-list-users [options]","text":"<p>Generate user list report. </p> <p>Notes: </p> <ol> <li>Use -I to include inactive allocations</li> <li> <ol> <li>for information for all resources, use \"-r all\"</li> </ol> </li> </ol>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list-users/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"allocation-management/not_in_nav/sbank-list-users/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"allocation-management/not_in_nav/sbank-list-users/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>also get inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:    - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==.  <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list-users/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list/","title":"Manpage for sbank-list","text":""},{"location":"allocation-management/not_in_nav/sbank-list/#sbank-list-options","title":"sbank-list  [options] <p>List Meta Command</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-list/#commands","title":"COMMANDS","text":"<ul> <li>allocations [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT) </li> <li>categories [-f|-n|-w|...] messages [-f|-n|-w|...] names [-f|-n|-w|...] </li> <li>jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...] </li> <li>transactions [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</li> </ul>"},{"location":"allocation-management/not_in_nav/sbank-list/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-list/#-a-allocation","title":"-a --allocation","text":"<p>enter allocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-c-comment","title":"-c --comment","text":"<p>enter comment for new or edit commands, display comment for list commands</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-e-event-id","title":"-e --event-id","text":"<p>enter event db id; event db id is an internal id created by the charging system</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-f-field","title":"-f --field","text":"<p>enter [:], width is optional; enter -f? or -f \"?\" for available fields, + to add fields"},{"location":"allocation-management/not_in_nav/sbank-list/#-h-help","title":"-h --help","text":"<p>command line help</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-j-jobid","title":"-j --jobid","text":"<p>enter jobid; jobid is created by the scheduler and is not unique</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-n-num-field","title":"-n --num-field","text":"<p>enter number of fields to display</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-p-project","title":"-p --project","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-r-resource","title":"-r --resource","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-s-suballocation","title":"-s --suballocation","text":"<p>enter suballocation id</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-t-transaction","title":"-t --transaction","text":"<p>enter transaction id</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-u-user","title":"-u --user","text":"<p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-w-field-width","title":"-w --field-width","text":"<p>enter the field width as follows: :, enter -w? or -w \"?\" for available fields"},{"location":"allocation-management/not_in_nav/sbank-list/#-e-end","title":"-E --end","text":"<p>enter end datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-h-human-readable","title":"-H --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-i-get-inactive","title":"-I --get-inactive","text":"<p>include inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-o-get-only-inactive","title":"-O --get-only-inactive","text":"<p>include inactive allocations</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-s-start","title":"-S --start","text":"<p>enter start datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-t-type","title":"-T --Type","text":"<p>enter type of transaction</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-all-charges","title":"--all-charges","text":"<p>for list allocations | projects | users, only show info with charges</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-at","title":"--at","text":"<p>enter transaction-created datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-award-category","title":"--award-category","text":"<p>enter allocation award category</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-award-type-name","title":"--award-type-name","text":"<p>enter allocation award-type name</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-created","title":"--created","text":"<p>enter created datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-debug","title":"--debug","text":"<p>enter debug level</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-get-deleted","title":"--get-deleted","text":"<p>get deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-get-not-charged","title":"--get-not-charged","text":"<p>get jobs that have not been charged</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-get-only-deleted","title":"--get-only-deleted","text":"<p>get only deleted objects</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-history-date-range","title":"--history-date-range","text":"<p>enter history datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-last-updated","title":"--last-updated","text":"<p>enter last updated datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma-separated thousands</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-header","title":"--no-header","text":"<p>do not display header</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-history","title":"--no-history","text":"<p>do not display history information</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-rows","title":"--no-rows","text":"<p>do not display rows</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-no-totals","title":"--no-totals","text":"<p>do not display totals</p>"},{"location":"allocation-management/not_in_nav/sbank-list/#-queued","title":"--queued","text":"<p>enter queued datetime filter</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/","title":"Manpage for sbank Commands","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#sbank-options","title":"sbank   [options]","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#description","title":"DESCRIPTION","text":"<p>HPC Accounting System Command Line Interface</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#detail-meta-command","title":"detail meta command","text":"<p>\"detail\" meta command displays information in a long format with history updates, where appropriate.</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#list-meta-command","title":"list meta command","text":"<p>\"list\" meta command displays information in a table format, but no history updates are displayed.</p> <p>IMPORTANT NOTES   1. All dates entered shall be interpreted as UTC   2. non-admin users will only be able to see their content (jobs, charges, etc.)   3. project admin users will be able to see all of the content for their projects   4. staff admin users will be able to see all the content   5. --help and -h are the help options.</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#meta-commands","title":"META COMMANDS","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-detail-options","title":"- detail  [options]","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-list-options-default","title":"- list  [options] (DEFAULT) <p>DETAIL COMMANDS   * allocations [-a | -e |-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] [ ... ] (DEFAULT)    * jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] [ ... ]    * projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...] [ ... ]    * transactions [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] [ ... ]    * users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...] [ ... ] <p>LIST COMMANDS   * allocations [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT)    * jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...]    * transactions [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...]    * users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#options","title":"OPTIONS","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-a-allocation","title":"-a --allocation <p>enter allocation id</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-c-comment","title":"-c --comment <p>enter comment for new or edit commands, display comment for list commands</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-e-event-id","title":"-e --event-id <p>enter event db id; event db id is an internal id created by the charging system</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-f-field","title":"-f --field <p>enter [:], width is optional; enter -f? or -f \"?\" for available fields, + to add fields","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-h-help","title":"-h --help <p>command line help</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-j-jobid","title":"-j --jobid <p>enter jobid; jobid is created by the scheduler and is not unique</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-n-num-field","title":"-n --num-field <p>enter number of fields to display</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-p-project","title":"-p --project <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-r-resource","title":"-r --resource <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-s-suballocation","title":"-s --suballocation <p>enter suballocation id</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-t-transaction","title":"-t --transaction <p>enter transaction id</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-u-user","title":"-u --user <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-w-field-width","title":"-w --field-width <p>enter the field width as follows: :, enter -w? or -w \"?\" for available fields","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-e-end","title":"-E --end <p>enter end datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-h-human-readable","title":"-H --human-readable <p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-i-get-inactive","title":"-I --get-inactive <p>include inactive allocations</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-o-get-only-inactive","title":"-O --get-only-inactive <p>get only inactive allocations</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-s-start","title":"-S --start <p>enter start datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-t-type","title":"-T --Type <p>enter type of transaction</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-all-charges","title":"--all-charges <p>for list allocations | projects | users, only show info with charges</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-at","title":"--at <p>enter transaction-created datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-award-category","title":"--award-category <p>enter allocation award category</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-award-type-name","title":"--award-type-name <p>enter allocation award-type name</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-created","title":"--created <p>enter created datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-debug","title":"--debug <p>enter debug level</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-get-deleted","title":"--get-deleted <p>get deleted objects</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-get-not-charged","title":"--get-not-charged <p>get jobs that have not been charged</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-get-only-deleted","title":"--get-only-deleted <p>get only deleted objects</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-history-date-range","title":"--history-date-range <p>enter history datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-home-dir","title":"--home-dir <p>enter the directory to store the pbs meta file</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-ignore-pbs-files","title":"--ignore-pbs-files <p>all new pbs files will be ignored and marked as processed</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-last-updated","title":"--last-updated <p>enter last updated datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-commas","title":"--no-commas <p>remove commas from comma-separated thousands</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-header","title":"--no-header <p>do not display header</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-history","title":"--no-history <p>do not display history information</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-rows","title":"--no-rows <p>do not display rows</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-sys-msg","title":"--no-sys-msg <p>do not display system message</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-no-totals","title":"--no-totals <p>do not display totals</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#-queued","title":"--queued <p>enter queued datetime filter</p>","text":""},{"location":"allocation-management/not_in_nav/sbank-manpage/#more-option-explanations","title":"MORE OPTION EXPLANATIONS","text":"<p>For -a, -e, -f, -w, -j, -p, -r, -t, -u, -T, --award-categories, --award_type_names, --cbank_refs options:</p> <p>These options can be entered multiple times for different values or entered once for multiple values. </p> <p>Examples: </p> <ol> <li> <p>sbank-list-allocation -u \"pershey rojas allcock\" or &gt; sbank-list-allocation -u pershey -u rojas -u allcock </p> </li> <li> <p>sbank-list-allocation -f \"id p avail\" or &gt; sbank-list-allocation -f id -f p -f avail For -u, -p and -r the use of wild card \"*\" is allowed, but only on names, not ids: </p> </li> </ol> <p>Examples: </p> <ol> <li>The following command will find allocations for users whose names start with \"pers\" and also users rojas and allcock. &gt; sbank-list-allocation -u \"pers* rojas allcock\" </li> <li>The following command will find allocations for projects that contain \"ratio\" in the name. &gt; sbank-list-allocation -p ratio </li> <li>The following command will find allocations for projects that end with \"tion\" in the name. &gt; sbank-list-allocation -p *tion </li> <li>The following command will find allocations for projects that start with \"ab\" and end with \"ng\" in the name. &gt; sbank-list-allocation -p ab*ng</li> </ol> <p>For -f option: This option is the display field option. </p> <p>To get the available fields enter -f? or -f \"?\". Default fields columns will be displayed if no field option is specified. </p> <p>To replace the current fields to display, enter: </p> <pre><code>&gt; sbank-list-allocations ... -f \"FIELD[:WIDTH]...FIELD[:WIDTH]\" or &gt; sbank-list-allocations ... -f FIELD[:WIDTH] ... -f FIELD[:WIDTH] \n</code></pre> <p>If you wish to add fields to the default fields, enter one + symbol anywhere in the quoted string: </p> <pre><code>&gt; sbank-list-allocations ... -f \"+ FIELD[:WIDTH]...FIELD[:WIDTH]\", only one + symbol is needed.\n</code></pre> <p>The fields will be displayed in table format and in the order entered in the command line. You can specify the field width, where WIDTH can be positive or negative value. Left alignment use -, right alignment use + or nothing.</p> <p>For -w option:</p> <p>FIELD:WIDTH, if the field is displayed it will change the width for the specified field. </p> <p>NOTE: This will not add the field as in -f option, only change the width. To get available fields you can also use -w? or -w \"?\" as in -f option.</p> <p>For -S, -E, --created, --queued, --last-updated, --history-date-range options:</p> <p>These are the date filter options. All dates are treated as UTC. </p> <p>You can use any reasonable date string that resembles a date Ambiguous dates will be parsed with the following parsing precedence: **YEAR then MONTH then DAY **</p> <p>For example, 10-11-12 or 101112 will be the following date: Oct. 11, 2012 Not: Nov. 12, 2010 or Nov. 10, 2012 </p> <p>Or you can specify a single date as follows: </p> <pre><code>\"[OPER]UTC_DATE\" You can specify a date range as follows: \n\"[OPER1]UTC_DATE1...[OPER2]UTC_DATE2\" Where OPER can be one of the following operators: \"==\", \"&gt;=\", \"&lt;=\", \"&gt;\", \"&lt;\" or \"eq\", \"ge\", \"le\", \"gt\", \"lt\" \n</code></pre> <p>Note: The following defaults for OPER, OPER1, OPER2 for the following options: </p> <pre><code>Options OPER OPER1 OPER2 ------------------------- ---- ----- ----- -E, &lt; &gt;= &lt; -S, &gt;= &gt;= &lt; --at &gt;= &gt;= &lt; --created &gt;= &gt;= &lt; --eligible &gt;= &gt;= &lt; --last-updated &gt;= &gt;= &lt; --queued &gt;= &gt;= &lt; \n</code></pre> <p>You can also use the following key letters \"n\", \"t\", \"d\", \"w\", \"y\" as follows: </p> <pre><code>KEY SYNTAX DEFINITIONS ---------- ----------- n[ow] now, where \"now\" is current-date current-time UTC t[oday] today, where \"today\" is current-date 00:00:00 UTC [+/-]d specified \"number\" of +/- days from \"today\" in UTC [+/-]w specified \"number\" of +/- weeks from \"today\" in UTC [+/-]y specified \"number\" of +/- years from \"today\" in UTC\n</code></pre> <p>For -T option:</p> <p>Transaction type option. The following are the valid transaction types and their explanation: CHARGE filter on job charges PULLBACK filter on allocation pullbacks DEPOSIT filter on allocation deposits REFUND filter on job refunds VOID filter on void transactions</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#invocation","title":"INVOCATION","text":"<p>sbank sbank sbank sbank-detail sbank detail sbank d sbank-detail-allocations sbank detail allocations sbank d a sbank-detail-jobs sbank detail jobs sbank d j sbank-detail-projects sbank detail project sbank d p sbank-detail-transactions sbank detail transactions sbank d t sbank-detail-users sbank detail users sbank d u sbank-list sbank list sbank l sbank-list-allocations sbank list allocations sbank l a sbank-list-jobs sbank list jobs sbank l j sbank-list-projects sbank list projects sbank l p sbank-list-transactions sbank list transactions sbank l t sbank-list-users sbank list users sbank l u</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#environment-variables","title":"ENVIRONMENT VARIABLES","text":"<p>Command line default options: Define the following environment variables as you would in the command line. Once the environment variable is defined, it will be used as the default options and arguments for the specific command. Command line options will take precedence.</p> <p>sbank_DETAIL_ALLOCATIONS_ARGS</p> <p>Default arguments and options for sbank-detail-allocations.</p> <p>sbank_DETAIL_CATEGORIES_ARGS</p> <p>Default arguments and options for sbank-detail-categories.</p> <p>sbank_DETAIL_NAMES_ARGS</p> <p>Default arguments and options for sbank-detail-names.</p> <p>sbank_DETAIL_MESSAGES_ARGS</p> <p>Default arguments and options for sbank-detail-messages.</p> <p>sbank_DETAIL_JOBS_ARGS</p> <p>Default arguments and options for sbank-detail-jobs.</p> <p>sbank_DETAIL_PROJECTS_ARGS</p> <p>Default arguments and options for sbank-detail-projects.</p> <p>sbank_DETAIL_TRANSACTIONS_ARGS</p> <p>Default arguments and options for sbank-detail-transactions.</p> <p>sbank_DETAIL_USERS_ARGS</p> <p>Default arguments and options for sbank-detail-users.</p> <p>sbank_LIST_ALLOCATIONS_ARGS</p> <p>Default arguments and options for sbank-list-allocations.</p> <p>sbank_LIST_JOBS_ARGS</p> <p>Default arguments and options for sbank-list-jobs.</p> <p>sbank_LIST_PROJECTS_ARGS</p> <p>Default arguments and options for sbank-list-projects.</p> <p>sbank_LIST_TRANSACTIONS_ARGS</p> <p>Default arguments and options for sbank-list-transactions.</p> <p>sbank_LIST_USERS_ARGS</p> <p>Default arguments and options for sbank-list-users.</p>"},{"location":"allocation-management/not_in_nav/sbank-manpage/#examples","title":"EXAMPLES <p>Example 1: -f, --field</p> <pre><code>&gt; sbank-list-transactions ... -f field1:-20 -f field2:20 -f field3 or &gt; sbank-list-transactions ... -f \"field1:-20 field2:20 field3\" \n</code></pre> <p>Explanation: Fields will be displayed in order of appearance, where field1:-20 means 20 characters long, left align; where field2:20 means 20 characters long, right align; where field3 uses default sizes. Number fields default to right aligned. Text fields default to left aligned.</p> <p>Example 2: -S, -E, --created, --queued, --last-updated, --history-start, --history-end</p> <p>Single date-string examples: </p> <ul> <li>  <p>sbank-list-allocations -S \"&gt;=Oct 11, 2014\" start dates that are &gt;= \"2014-10-11 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&lt;=2014-11-10\" start dates that are &lt;= \"2014-11-10 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -E \"&lt;20141110\" end dates that are &lt; \"2014-11-10 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -E \"22:30:10\" end dates that are &lt; \" 22:30:10\"    <li>  <p>sbank-list-allocations -S \"&gt;today\" start dates that are &gt; \" 00:00:00\"    <li>  <p>sbank-list-allocations -E t end dates that are &lt; \" 00:00:00\"    <li>  <p>sbank-list-allocations -S gtnow start dates that are &gt; \" \"    <li>  <p>sbank-list-allocations -E len end dates that are &lt;= \" \"    <li>  <p>sbank-list-allocations -S \"1d\" start dates that are &gt;= \"today +1 day\" </p>  </li> <li>  <p>sbank-list-allocations -E \"-2w\" end dates that are &lt; \"today -2 weeks\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&gt;=1y\" start dates that are &gt;= \"today +1 year\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&gt;2012\" start dates that are &gt; \"2012-- 00:00:00\"     <p>Range date-string examples: </p> <ul> <li>  <p>sbank-list-allocations -S \"2013-01-01...2014-01-01\" \"2013-01-01\" &lt;= DATES &lt; \"2014-01-01\" </p>  </li> <li>  <p>sbank-list-allocations -S \"-1y...t\" \"today -1 year\" &lt;= DATES &lt; \"today\" </p>  </li> <li>  <p>sbank-list-allocations -E \"2013...t\"\" \"2013--\" &lt;= DATES &lt; \"today\"    <li>  <p>sbank-list-allocations -E \"&gt;2013...&lt;=t\"\" \"2013--\" &lt; DATES &lt;= \"today\"    <p>Example 3: Command invocation examples</p> <ul> <li>  <p>sbank-list-projects list projects full command invocation </p>  </li> <li>  <p>sbank list projects list projects meta command invocation</p>  </li> <li>  <p>sbank s p list projects partial meta command invocation </p>  </li> <li>  <p>sbank p list projects where \"list\" is the default</p>  </li> <li>  <p>sbank list allocations is the default </p>  </li> <li>  <p>sbank a list allocations \"list\" is the default </p>  </li> <li>  <p>sbank s a list allocations partial meta command invocation</p>  </li> </ul> <p>Example 4: -h, --help</p> <ul> <li>  <p>sbank -h will give you help summary on all of sbank </p>  </li> <li>  <p>sbank list --help will give you help on all the \"list\" commands </p>  </li> <li>  <p>sbank list allocations -h will give you help on the \"list allocations\" command</p>  </li> <li>  <p>sbank-list-allocations -h will give you help on the \"list allocations\" command </p>  </li> <li>  <p>sbank l a --help will give you help on the \"list allocations\" command</p>  </li> </ul>","text":""},{"location":"bebop/bebop-rebuild-faq/","title":"Bebop Rebuild FAQ","text":""},{"location":"bebop/bebop-rebuild-faq/#overview","title":"Overview","text":"<p>On July 1, 2024, Bebop was rebuilt from CentOS 7 to Rocky Linux 8 as CentOS has reached End of Life. This rebuild includes a full Operating System change, a new software tree and a transition from Slurm to PBS Professional as the system job scheduler.</p>"},{"location":"bebop/bebop-rebuild-faq/#logging-in","title":"Logging In","text":"<p>As before, to access Bebop, use the following command:</p> <p><code>ssh &lt;your_argonne_username&gt;@bebop.lcrc.anl.gov</code></p> <p>However, because the login nodes SSH Known Host Keys have changed, you may see something like the following message:</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the RSA key sent by the remote host is\nSHA256:XXXXXXXXXXXXXXXXXXXXXXXXXXX.\nPlease contact your system administrator.\nAdd correct host key in ~/.ssh/known_hosts to get rid of this message.\nOffending RSA key in ~/.ssh/known_hosts:13\nPassword authentication is disabled to avoid man-in-the-middle attacks.\nKeyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.\n</code></pre> <p>This is expected! To bypass this message in the future, please note the line:</p> <p><code>Offending RSA key in ~/.ssh/known_hosts:13</code></p> <p>In this instance, you would delete line 13 from the <code>~/.ssh/known_hosts</code> file on your local machine. The line number(s) will be different for everyone.  You will need to do this for any Bebop login node in this file. You can search this file for any of the following and delete those lines:</p> <ul> <li>bebop.lcrc.anl.gov</li> <li>beboplogin[1-6].lcrc.anl.gov</li> <li>140.221.70.[5-10]</li> </ul>"},{"location":"bebop/bebop-rebuild-faq/#submitting-and-running-jobs","title":"Submitting and Running Jobs","text":"<p>Bebop is now using the PBS Professional job scheduler which replaces Slurm. With this change, we have removed the following queues: <code>bdw</code>, <code>bdws</code>, and <code>bdwd</code>. As a reminder, all KNL queues were previously retired in early 2024.</p> <p>All jobs should now be submitted to the queue: <code>bdwall</code>. This is also the default queue. If you still need to submit to Broadwell nodes with a large local scratch disk, we have outlined how to do that here: </p> <p>https://docs.lcrc.anl.gov/bebop/running-jobs-bebop</p> <p>For tips on how to use PBS, please see:</p> <p>https://docs.lcrc.anl.gov/running-jobs-at-lcrc/pbs-pro-clusters</p> <p>Like our login nodes, all SSH Known Host keys have changed on the Bebop compute nodes. Because of this, you may get an error when trying to submit single node, multi-node or interactive jobs to any of the queues/compute nodes. We highly recommend ALL users run the following after logging into a Bebop login node:</p> <p><code>mv ~/.ssh/known_hosts ~/.ssh/known_hosts.bak</code></p> <p>If you see any code errors, MPI errors or SSH/Host Key errors when running a job, we recommend trying this first before contacting support. The above command will move your current LCRC SSH Known Hosts file to a backup file which should prevent any host connection errors.</p>"},{"location":"bebop/bebop-rebuild-faq/#faq","title":"FAQ","text":""},{"location":"bebop/bebop-rebuild-faq/#i-use-x-software-and-it-is-missing-where-did-it-go","title":"I use \"X\" software and it is missing, where did it go?","text":"<p>Prior to the Bebop rebuild, LCRC staff sent several e-mails to LCRC users. Users were informed that the previous stack of software would be removed in favor of a new one. The old software was removed since we've installed ~8 years of software and the software tree has grown too large to maintain. More importantly, most of the previous software was built with the old OS system packages and libraries and would simply be incompatible with the rebuilt OS.</p> <p>LCRC staff have already installed several compilers and MPI variants as well as some standard packages. We've asked users to let us know if they need any software re-installed. If we have not been notified about a software request, the expectation will be that it won't be installed. We will gladly try to assist in installing software globally if it useful to several LCRC users, otherwise we encourage building and compiling in your project directories.</p> <p>If you have software built in your home and/or project directories prior to the rebuild, you are more than welcome to try and use it. However, if it does not work correctly or at all, you should recompile your software. Anything that links to the old software tree is subject to stop working once we permanently delete the old tree in the near future.</p> <p>Please e-mail support@lcrc.anl.gov with any software requests.</p>"},{"location":"bebop/bebop-rebuild-faq/#what-software-modules-are-now-loaded-by-default","title":"What software modules are now loaded by default?","text":"<p>We have decided against loading any software modules by default going forward. We hope to phase out older modules after a certain amount of time to reduce software installation bloat on  the system and to encourage the use of newer software. Compilers and MPI versions will need to be loaded and/or saved to load on login by the user. When we do decide to retire old software, we will send an announcement with a generous lead time.</p>"},{"location":"bebop/bebop-rebuild-faq/#do-i-still-request-allocations-on-bebop-in-core-hours","title":"Do I still request allocations on Bebop in Core Hours?","text":"<p>Bebop is now calculating allocations in Node Hours instead of Core Hours. This is also how we set allocations on the Improv cluster. You should request time on Bebop for future quarters in Node Hours. For FY24 Q4, we have already converted previously submitted Core Hours to Node Hours on your behalf. For quick reference:</p> <p><code>1 Bebop Node Hour = 36 Core Hours</code></p> <p>https://docs.lcrc.anl.gov/allocation-management/allocations</p>"},{"location":"bebop/bebop-rebuild-faq/#i-have-a-condo-queue-on-the-bebop-cluster-what-account-should-i-use-to-submit-my-jobs","title":"I have a condo queue on the Bebop cluster. What account should I use to submit my jobs?","text":"<p>Previously, condo queue users would submit jobs to their queues on Bebop with the <code>condo</code> account in Slurm. This has changed with PBS. Going forward, you should submit your jobs with the same account that is used to access your condo nodes. The following is a list of condo queues and the account that should be used:</p> Condo Queue New Account Name csed g-CSE dis g-DIS es g-ES es-mpc g-ES-mpc esd g-ESd hepd g-HEP or g-ATLAS phyd g-Physics xsd g-XSD <p>As before, condo queues do not restrict usage based on node hour availability, however, an account is required to submit jobs.</p>"},{"location":"bebop/bebop-rebuild-faq/#i-am-new-to-the-cluster-are-startup-accounts-still-available","title":"I am new to the cluster. Are startup accounts still available?","text":"<p>With the transition to PBS, we are not currently using startup accounts. If you need to run on Bebop, you should either join an LCRC project or request a new one via the accounts page. Please see our documentation about LCRC projects here:</p> <p>https://docs.lcrc.anl.gov/account-project-management/project-management</p>"},{"location":"bebop/bebop-rebuild-faq/#my-jobs-are-failing-with-strange-mpi-code-ssh-or-host-key-verification-failures-what-can-i-do","title":"My jobs are failing with strange MPI, code, SSH or Host Key Verification failures. What can I do?","text":"<p>As mentioned above, run the following after logging into a Bebop login node: </p> <p><code>mv ~/.ssh/known_hosts ~/.ssh/known_hosts.bak</code></p> <p>The above command will move your current LCRC SSH Known Hosts file to a backup file which should prevent any host connection errors. Please make sure to try this before contacting LCRC support with any MPI, code or SSH errors from your jobs.</p>"},{"location":"bebop/bebop-rebuild-faq/#i-cannot-find-x-documentation-on-the-lcrc-website-what-should-i-do","title":"I cannot find \"X\" documentation on the LCRC website. What should I do?","text":"<p>We have a lot of documentation for Bebop on the LCRC website and will be working to update this in the days and weeks following the rebuild. If something is missing or inaccurate, feel free to let us know by sending e-mail to support@lcrc.anl.gov.</p>"},{"location":"bebop/bebop-rebuild-faq/#getting-support","title":"Getting Support","text":"<p>If you have any questions or issues following the rebuild, please e-mail support@lcrc.anl.gov and LCRC staff will assist you.</p>"},{"location":"bebop/getting-started-bebop/","title":"Getting Started on Bebop","text":""},{"location":"bebop/getting-started-bebop/#accessing-bebop","title":"Accessing Bebop","text":"<p>Due to updated security requirements, direct SSH access to Bebop is no longer permitted. All inbound access must now go through the CELS login nodes using a jump host configuration.</p> <p>You cannot SSH directly into the CELS login nodes. Instead, connect using the command below (replacing <code>&lt;username&gt;</code> and <code>&lt;ssh_private_key&gt;</code> accordingly):</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@bebop.lcrc.anl.gov\n</code></pre> <p>Alternatively, you can simplify future connections by adding the following block to your <code>~/.ssh/config</code>:</p> <pre><code>Host logins.lcrc.anl.gov\n  HostName logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost bebop.lcrc.anl.gov bebop\n  HostName bebop.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n</code></pre> <p>After configuring this, you can connect with either:</p> <pre><code>ssh bebop.lcrc.anl.gov\n</code></pre> <p>or simply:</p> <pre><code>ssh bebop\n</code></pre> <p>Note: The logins.lcrc.anl.gov alias is provided as part of LCRC's integration with CELS login infrastructure.</p>"},{"location":"bebop/getting-started-bebop/#system-architecture","title":"System Architecture","text":"<p>For a detailed overview of Bebop, including the compute node architecture, refer to the Hardware Overview page.</p>"},{"location":"bebop/getting-started-bebop/#job-execution","title":"Job Execution","text":"<p>For information on how to run jobs on Bebop, refer to the Running Jobs page.</p>"},{"location":"bebop/getting-started-bebop/#bebop-rebuild-faq","title":"Bebop Rebuild FAQ","text":"<p>On July 1, 2024, Bebop was rebuilt with a new operating system, featuring an entirely new software tree and a transition from Slurm to PBS Professional as the job scheduler. If you haven't logged in for a while and are experiencing connection issues, or for more details about these changes, please refer to our Bebop Rebuild FAQ here.</p>"},{"location":"bebop/hardware-overview-bebop/","title":"Bebop Hardware Overview","text":"<p>Bebop has 672 compute nodes with Intel Broadwell CPUs (352 KNL nodes were previously retired). The Broadwell nodes have DDR4 memory, and 64 nodes have a 4TB HDD for scratch disk. The high-performance interconnect is Intel Omni-Path (OPA) 100G. There are 12 OPA connections to LCRC\u2019s existing data storage system so you will have access to all of the same files between LCRC clusters.</p>"},{"location":"bebop/hardware-overview-bebop/#bebop-compute-nodes","title":"Bebop Compute Nodes","text":"<p>672 Broadwell Nodes</p> Bebop Broadwell Description Per Node Aggregate Processor Intel Xeon E5-2695v4 2 Sockets 1,344 Cores/Threads 18 Cores/1 Thread per core 36 24,192/24,192 Memory DDR4 128 GiB 86,016 GiB Local SSD 4 TB (Nodes bdwd-[0001-0064]) 1 256 TB"},{"location":"bebop/hardware-overview-bebop/#bebop-login-nodes","title":"Bebop Login Nodes","text":"<p>There are five login nodes available to users for editing code, building code, submitting/monitoring jobs, checking usage (<code>sbank</code>), etc. Their full hostnames are <code>beboploginN.lcrc.anl.gov</code> for <code>N</code> equal to <code>1</code> through <code>5</code>. The login nodes hardware is identical to the compute nodes. The various compilers and libraries are present on the logins, so most users should be able to build their code. All users share the same login nodes so please be courteous and respectful of your fellow users. For example, please do not run computationally or IO intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.</p> <p>Individual user processes on the login nodes will be throttled temporarily for those that exceed 8 CPUs and 8GB of RAM.</p>"},{"location":"bebop/running-jobs-bebop/","title":"Running Jobs on Bebop","text":"<p>NOTE:  On July 1, 2024, Bebop was rebuilt from CentOS 7 to Rocky Linux 8 as CentOS has reached End of Life. This rebuild includes a full Operating System change, a new software tree and a transition from Slurm to PBS Professional as the system job scheduler. Please see our Bebop Rebuild FAQ for more details.</p>"},{"location":"bebop/running-jobs-bebop/#quickstart","title":"Quickstart","text":"<p>Presented below are fundamental commands essential for day-to-day use by most LCRC users on Bebop. Comprehensive guides are available in other sections linked within our documentation.</p> <p>Check your Current Allocation Balance(s):</p> <pre><code>sbank-list-allocations -p &lt;project_name&gt;\n</code></pre> <p>Check your Filesystem Quota(s):</p> <pre><code>lcrc-quota\n</code></pre> <p>Submit a Batch Job:</p> <pre><code>qsub -A &lt;project&gt; &lt;your job script&gt;\n</code></pre> <p>List All Jobs:</p> <pre><code>qstat\n</code></pre> <p>Delete a Job:</p> <pre><code>qdel &lt;jobid&gt;\n</code></pre>"},{"location":"bebop/running-jobs-bebop/#job-scheduling-system","title":"Job Scheduling System","text":"<p>Bebop's job scheduling system is characterized by:</p> <ul> <li>Uses PBS Pro</li> <li>Uses the <code>sbank</code> accounting system</li> <li>Allocations are calculated in node hours</li> </ul>"},{"location":"bebop/running-jobs-bebop/#queues","title":"Queues","text":"<p>Bebop currently enforces the following limits on publicly available queues:</p> <ul> <li>32 Running Jobs per user.</li> <li>100 Queued Jobs per user.</li> <li>40 Running Nodes per user.</li> <li>60 Running Nodes per project.</li> <li>3 Days (72 Hours) Maximum Walltime.</li> <li>1 Hour Default Walltime if not specified.</li> <li>bdwall (Broadwell Compute Nodes) is the default queue.</li> </ul> <p>Use the -q option with qsub to select a queue.</p> Bebop Queue Name Description Number of Nodes CPU Type Cores Per Node Memory Per Node Local Scratch Disk bdwall All Broadwell Nodes 672 Intel Xeon E5-2695v4 36 128GB DDR4 15 GB or 4 TB backfill All Broadwell Nodes 672 Intel Xeon E5-2695v4 36 128GB DDR4 15 GB or 4 TB"},{"location":"bebop/running-jobs-bebop/#special-request-for-large-local-scratch-disk","title":"Special Request for Large Local Scratch Disk","text":"<p>The bdwall queue also has 64 nodes with a 4TB local scratch disk. You can request these directly by adding bigdata=true to your PBS select statement. For example:</p> <pre><code>#PBS -l select=1:ncpus=36:mpiprocs=36:bigdata=true\n</code></pre>"},{"location":"bebop/running-jobs-bebop/#backfill-queue","title":"Backfill Queue","text":"<p>The backfill queue is used to improve the overall efficiency of the cluster by utilizing idle resources that would otherwise remain unused. Only jobs that ran out of hours may use the backfill queue, and the maximum wall-time is 4 hours. Users can submit jobs to the backfill queue by specifying it as the target queue in the PBS select statement. For example:</p> <pre><code>#PBS -q backfill\n</code></pre> <p>An example for interactive jobs:</p> <pre><code>qsub -q backfill -l select=1:ncpus=36:mpiprocs=36 -l walltime=15:00 -A support -I\n</code></pre>"},{"location":"bebop/running-jobs-bebop/#job-submission-examples","title":"Job Submission Examples","text":""},{"location":"bebop/running-jobs-bebop/#example-qsub-job-submission","title":"Example <code>qsub</code> Job Submission","text":""},{"location":"bebop/running-jobs-bebop/#example-interactive-job-submission","title":"Example Interactive Job Submission","text":""},{"location":"best-practices-and-policies/allocation-expiration-policy/","title":"Allocation Expiration Policy","text":"<p>LCRC clusters are very heavily used, so the computer time your project has been given is a valuable resource. LCRC allocations are granted on the first day of the new fiscal quarter at midnight.</p> <p>At the end of each fiscal quarter, any remaining time available in your project balances will be completely removed from your bank. There is no carry over between quarters.</p> <p>Fiscal quarters are divided into the following time frames:</p> <ul> <li>1st Quarter (October 1 \u2013 December 31)</li> <li>2nd Quarter (January 1 \u2013 March 31)</li> <li>3rd Quarter (April 1 \u2013 June 30)</li> <li>4th Quarter (July 1 \u2013 September 30)</li> </ul>"},{"location":"best-practices-and-policies/allocation-request-policy/","title":"Allocation Requests Policy","text":"<p>All allocation requests, mid-quarter or at the start of the year, should be self-contained and include complete details on node-hour-computations such as typical number of nodes and cores per case, typical run time per case and total number of cases planned per quarter. For large requests, justification for the typical number of nodes per case should be provided based on scaling studies. A large request is typically at or above 4000 node-hours on Improv, 14000 node-hours on Bebop and 120 GPU node-hours on Swing. (For select cases, PIs may be requested to provide scaling results for requests below these limits as well).</p> <p>Please follow the instructions below the \"Request Allocation\" subsection on the LCRC Accounts page when creating or updating a project to complete the allocation request. Please review the sample project report in the link provided below the \"Request allocation\" box on the allocation page (sections \"Experiments planned &amp; size of calculations\" and \"Large allocation efficiency\"). Please do not submit one-line requests stating request is based on past experience/usage. The allocation committee does not have access to this information. Such requests will be considered incomplete and ineligible for review.</p> <p>The strong scaling study is required to justify the choice of the number of nodes used to compute the node-hour request. Please present the scaling studies in text form in the \"Request allocation\" box as shown in the screenshot in the example link. Do not attach separate .doc/png/pdf files to your allocation request. A publication which shows scaling on an old machine on a different problem does not qualify as a scaling study. It can be used as a basis for the scaling study, though. The scaling study has to justify the use of the nodes to be used in the problem described in the allocation request and conducted on LCRC clusters. New projects can be granted a small initial allocation to complete the scaling study, if required.</p> <p>Request for time on all partitions (Bebop, Improv, Swing) should be in node-hours. The node-hour computations shown in the \"Request allocation\" box should match the node hours requested for each of the partitions. Please present your node-hour computations in the format shown in the sample allocation request. Providing incomplete/inaccurate or unclear information can delay the decision with regard to your allocation request or lead to a reduction in your requested allocation. PIs might not be granted their full allocation request. Allocations grants are made by the allocation committee after considering various factors such as the total time available versus the total requests from PIs across the lab, past usage of the PI/project and the computational readiness of the project.</p> <p>Projects that have exhausted their initial quarterly allocation should use the backfill queue.  The backfill queue can be used only when the project has a negative balance.  Limited mid-quarter allocations are granted for new projects.  Mid-quarter allocation requests are reviewed once a week (Tuesday). PIs should budget at least one week for a response/decision on their allocation request - longer if the request is inaccurate/incomplete/unclear and does not follow the guidelines provided in the sample project request document. The maximum mid-quarter allocation request will be as follows: 2,000 node-hours on Improv, 7,000 node-hours on Bebop, 25 GPU node-hours on Swing. This amount is pro-rated based on the time remaining in the quarter.</p> <p>No allocations are made within two weeks before the quarter's end.  Project renewals are at the start of the fiscal year. Failing to renew before the allocation deadline results in the project being ineligible for allocation in Q1 (PIs/users in this project can run in backfill during this time). Projects not renewed at the start of the fiscal year can also have a reduced allocation from Q2-Q4.</p> <p>PIs who expect to use time for all the remaining quarters for a given allocation year (extending from October to September) should enter an allocation request for all quarters. If a PI has applied for time for only a single quarter, they will not automatically be granted allocations for the next quarter(s). A new request will be needed and the project will have to run in the backfill queue in the quarter in which the new request was made.</p> <p>All unused time at the end of the quarter is lost - they cannot be transferred to the next/later quarters.   Time granted on a given partition cannot be transferred/switched to another partition (except in cases where a software does not run due to system/software stack changes).</p> <p>PIs who request &gt; 15000 node-hours per quarter over all projects (Bebop/Improv) and 120 node-hours per quarter over all projects (Swing) will be required to provide a \"transition plan\" detailing how they plan to transition their work-loads to larger DoE clusters such as ALCF/NERSC or other national platforms supported by DoE for large computational projects.  PIs requiring large allocations should supplement their LCRC allocations with other computational resources (ALCF/NERSC or other national platforms supported by the program offices).</p>"},{"location":"best-practices-and-policies/best-practices-and-policies-overview/","title":"Best Practices and Policies Overview","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#monthly-maintenance-day","title":"Monthly Maintenance Day","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#allocation-expiration-policy","title":"Allocation Expiration Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#cybersecurity-policy","title":"Cybersecurity Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#data-policy","title":"Data Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#job-scheduling-policy","title":"Job Scheduling Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#reservation-policy","title":"Reservation Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#shared-resource-policy","title":"Shared Resource Policy","text":""},{"location":"best-practices-and-policies/best-practices-and-policies-overview/#ssh-policy","title":"SSH Policy","text":""},{"location":"best-practices-and-policies/cybersecurity-policy/","title":"Cybersecurity","text":"<p>Argonne National Laboratory has an aggressive cybersecurity program, combining expert staff with hardware and software capabilities that help protect against intrusion and detect attacks. Argonne\u2019s cybersecurity program is regularly reviewed by groups of external experts. Argonne staff also receive annual training in cybersecurity. While no site connected to the Internet is impervious, we have many safeguards.</p> <p>All interactions with LCRC computers use Secure Shell authentication, a cryptographic network protocol for secure data communication.</p> <p>For authorized users, access to data stored in LCRC is managed by standard Linux file access mechanisms, which enable the file owner to limit access to themselves or specific groups of users, typically the members of their project. We can also set up special groups, as needed.</p> <p>Note that the LCRC system administrators with root privileges are not constrained by the file permissions, and they have the capability to open and/or copy all files on the system. They can also assume a user\u2019s identity on the system. LCRC staff will never copy, expose, discuss, or in any other way communicate your project information to anyone outside of your project, the LCRC, or Argonne National Laboratory cybersecurity officials without your explicit permission unless required to do so by law. It is your responsibility to encrypt data if you wish to prevent its exposure under those circumstances.</p> <p>Generally speaking, administrators use these highly elevated privileges only when requested, or if a suspected problem/security issue exists. Following are instances where LCRC staff might look at your files:</p> <ul> <li>We may review .error, .output, and scheduler log files to determine if a job failure was due to user error or a system failure.</li> <li>If you request our assistance via any mechanism (for example, help ticket, direct personal email, in person, etc.), we interpret that request to be explicit permission to view your files if we think doing so will aid us in resolving your issue.</li> </ul> <p>We do not permit certain kinds of information on LCRC systems, including, but not limited to, personally identifiable information (data that falls under the Privacy Act of 1974, 5 U.S.C. 552a), classified information, unclassified controlled nuclear information (UCNI), naval nuclear propulsion information (NNPI), the design or development of nuclear, biological, or chemical weapons, or any weapons of mass destruction. The use of LCRC resources for personal or non-work-related activities is also prohibited. Project PIs are responsible for knowing whether their project generates any of these prohibited data types or information that falls under Export Control. Currently, the use of export-controlled codes is prohibited. For questions, please contact LCRC support, support@lcrc.anl.gov.</p>"},{"location":"best-practices-and-policies/data-policy/","title":"Data Policy","text":""},{"location":"best-practices-and-policies/data-policy/#use-of-proprietarylicensed-software","title":"Use of Proprietary/Licensed Software","text":"<p>All software used on LCRC systems must be appropriately acquired and used according to the licensing agreements. Possession or use of illegally copied software is prohibited. Users shall not copy copyrighted software, unless explicitly permitted by the copyright holder(s). Export-controlled codes and/or data is prohibited unless an exception has been applied for and granted by the LCRC team. Users granted access to controlled projects must only work with the controlled codes and data in the project space made available for this purpose, and not in any shared spaces such as global scratch or temporary spaces.</p>"},{"location":"best-practices-and-policies/data-policy/#prohibited-data","title":"Prohibited Data","text":"<p>The LCRC computer systems are operated as research systems and contain only data related to scientific research. Use of LCRC resources to store, manipulate, or remotely access any sensitive or national security information is prohibited unless documented and approved, by the PI and LCRC leadership. This includes, but is not limited to, personally identifiable information (data that falls under the Privacy Act of 1974, 5 U.S.C. 552a), controlled unclassified information (CUI) to include unclassified controlled nuclear information (UCNI), naval nuclear propulsion information (NNPI), International Traffic in Arms Relations (ITAR), the design or development of nuclear, biological, or chemical weapons, or any weapons of mass destruction. The use of LCRC resources for personal or non-work-related activities is also prohibited.</p>"},{"location":"best-practices-and-policies/data-policy/#export-control","title":"Export Control","text":"<p>All principal investigators using LCRC resources and LCRC staff members working with project teams are responsible for knowing whether their project generates any of these prohibited data types or information that falls under Export Control. For questions, contact the LCRC Support Team at support@lcrc.anl.gov.</p>"},{"location":"best-practices-and-policies/data-policy/#data-storage-systems","title":"Data Storage Systems","text":"<p>Data stored on LCRC resources should only be data directly related to work done on the LCRC systems. Currently, users have access to two storage spaces (1) home file system space (2) project space. The ability for projects to archive data to tape will also be available soon.</p> <p>The home file system space for each user is primarily intended to hold source codes, executable files, configuration files and other such files and is currently 100 GB. Beyond this 100 GB limit, write-access is denied and data will need to be deleted or moved to continue writes. All home directories are initially created with owner read/write/execute privileges. Users are free to give read/execute privileges to group/world if they desire on their own home directory. Group/world write access on home directories is prohibited. LCRC is not responsible for any access granted by the user beyond the defaults set at creation time. We recommend reviewing your home directory permissions at regular intervals.</p> <p>Data files from simulations should be stored in the project space allocated to each project. Each project is allocated 1 TB of space. PIs can request additional space with proper justification to LCRC. Each application is carefully reviewed by the LCRC team to determine if additional storage space is justified. It must be emphasized that the project space is shared between all members of a project. The project PIs should ensure that individual members of the project manage their simulation data files in order to not exceed the allocated storage space. LCRC has a soft limit of 1 TB and a hard limit of 2 TB. These limits imply that the system will allow a project to exceed the nominal soft limit of 1 TB but not the hard limit of 2 TB for 14 days. These flexible storage limits allows projects to complete simulations that might require higher storage for a period of 14 days without stopping an on-going simulation. However, no further writes are allowed after the project reaches the hard limit of 2 TB or is above the 1 TB limit beyond the 14-day period.</p> <p>When LCRC moves to a new shared storage system (roughly every 5-7 years) and if you have condo storage paid for on the old system, we have a couple of options. If your existing storage amounts to less than 50 terabytes, we will move your data over to the new storage for free, and there is no future charge. Otherwise, the lifetime of your purchased storage is 5 years after we first made the space available to the group. This may overlap the new storage availability. At the end of your 5 years, and if we have changed storage systems in the interim, your space reverts to the general pool (with advanced notice). Of course, you can buy new space to replace it if this is an option at the time.</p>"},{"location":"best-practices-and-policies/data-policy/#backupstape-archiving","title":"Backups/Tape Archiving","text":"<p>Please see our storage writeup for complete details on our backup and archive solution.</p>"},{"location":"best-practices-and-policies/data-policy/#storage-policy-for-ex-project-members","title":"Storage policy for ex-project members","text":"<p>Students, post-docs and Argonne staff members are encouraged to manage their home file systems and data files before their final departure day from Argonne. Please contact the support team at LCRC if you are unable to to do.</p>"},{"location":"best-practices-and-policies/job-scheduling-policy/","title":"Job Scheduling Policy","text":"<p>The current LCRC job scheduling policy is pretty flexible, allowing people to submit nearly any kind of job mix into the job queue. We have implemented a policy that prevents more than 32 jobs for any one user from running at one time and we also enforce a 100 job limit per user. In addition, we have a process for handling overdrawn projects and a priority scheduling policy, both of which are described below.</p> <p>It should also be noted that we have maintenance days on the second Monday of every month. Therefore, if your job requires more time than there is remaining before the maintenance period, your job will be held until after the maintenance period.</p>"},{"location":"best-practices-and-policies/job-scheduling-policy/#priority-scheduling","title":"Priority Scheduling","text":"<p>The priority scheduling policy is implemented using Maui queues. Jobs are submitted to a default queue, and Maui then routes the jobs to the appropriate priority queue based on the priority assigned to the job owner. The larger the priority number, the later a job will be run (i.e. a job with priority 1 will be run before a job with priority 2, if possible). Each user is assigned a priority based on their memberships in LCRC projects. If they are a member of multiple projects, they are assigned the largest priority number of the projects.</p> <p>The CSAC Allocations Committee has assigned a priority to each active LCRC project. If a project goes negative, its priority is set to priority level 5. For example, if project A has been assigned priority 3 by the committee and has a positive balance, jobs of members of project A are assigned priority 3. If project A goes negative, jobs of members of project A will then be assigned priority 5.</p> <p>Maui schedules jobs FIFO within each priority level. Priority 0 jobs are scheduled FIFO until no more priority 0 jobs will fit, then priority 1 jobs are scheduled FIFO until no more priority 1 jobs will fit, etc. Priority only affects jobs if not all jobs in the queue can be scheduled due to not enough resources. If two jobs of differing priority cannot both fit within existing resources, but either of them will fit, the job with the lower priority number will be run first.</p> <p>LCRC does not use job preemption so once a job has started, it will run until it is finished, aborts with an error, or is deleted by the owner or an administrator.</p>"},{"location":"best-practices-and-policies/job-scheduling-policy/#general-scheduling-guidelines","title":"General Scheduling Guidelines","text":"<p>LCRC is expected to support all kinds of different usage. We do not want to unnecessarily limit the kinds of work that could be done on the system. We would prefer to maintain a flexible scheduling policy based on the needs of the community rather than impose a strict policy.</p> <p>As a consequence of this liberal scheduling policy, there have been instances in the past where people inappropriately loaded up the machine, resulting in delays for everyone else. Unfortunately, as LCRC becomes more heavily used, this requires increased monitoring.</p> <p>We ask that all users follow these guidelines:</p> <ol> <li>Follow good queue etiquette. This means, among other things, don\u2019t submit jobs that use a large number of nodes that run for a long time. If your job uses several hundred nodes, limit the run time to a few hours. Likewise, if your job runs for several hundred hours, limit the number of nodes to less than a dozen or so. We do encourage large jobs and if they need to run for awhile, this is okay. With others using the system, we only ask to you to be mindful of this and to break up runs when possible.</li> <li>Clearly, some work will require use of the machine beyond those bounds. In those cases, please send a quick note to support@lcrc.anl.gov so that we can be aware of these. If necessary, we can arrange for a reservation and notify the community.</li> <li>If we get well-founded complaints from other users of the system about your jobs, we will attempt to contact you to determine the best course of action. However, under some circumstances, we may have to kill running jobs. We don\u2019t want to do this, but it has been necessary a few times.</li> <li>We strongly encourage checkpointing. Checkpointing not only allows you to recover from a job that has died unexpectedly, but can also allow you to break a long-running job into smaller chunks that are therefore easier to schedule.</li> </ol>"},{"location":"best-practices-and-policies/job-scheduling-policy/#process-for-overdrawn-lcrc-projects","title":"Process for Overdrawn LCRC Projects","text":"<ol> <li>The system automatically checks for LCRC projects that have exceeded their balance.</li> <li>The queue priority of overdrawn projects will drop automatically to priority level 5. For details on the scheduling policy, please see the priority scheduling section of this document.</li> <li>Overdrawn projects will be limited to running only one job per user at a time.</li> <li>A member of the LCRC staff will notify overdrawn projects via email (to all Project members) within one business day. We will also invite the PIs to submit a revised allocation request if needed.</li> <li>The PIs may request a change in the distribution of the current project allocation (e.g., some/all of their 2nd half time in the first half). LCRC staff may move up to 100K hours; larger requests need approval by the Allocations Committee.</li> <li>Alternately, the PIs may submit a revised allocation request, asking for more time. Increments of less than 200K hours will be managed by LCRC staff and reported to the Allocations Committee; larger requests need approval by the Allocations Committee.</li> <li>If no request is received, the overdrawn project will be suspended (unable to start new jobs) when its time use exceeds 100% overdrawn or 25K hours overdrawn, whichever comes first. This gives the project a cushion to finish up, to put in their revised request, or to make other arrangements.</li> </ol> <p>Projects are encouraged to contact LCRC staff when their project needs change, particularly when there are special needs. We will make every effort to find ways to meet your research needs. The Allocations Committee meets quarterly.</p>"},{"location":"best-practices-and-policies/monthly-maintenance-day/","title":"Monthly Maintenance Day","text":"<p>LCRC has the second Monday of every month set aside for system maintenance (software upgrades, hardware replacements, etc.) on all LCRC resources. Maintenance generally begins at 8AM CST. During this time, the cluster will be unavailable for all users. All compute nodes will be set offline and the login nodes may or may not be accessible (but may be rebooted at any time).</p> <p>We generally have the cluster available again by the end of the same day, however, depending on the scope of work to be done this could be longer.</p> <p>The compute nodes will be reserved for maintenance a week in advance. If any jobs are submitted that are scheduled to end after the maintenance period has begun, they will not run. Leading up to maintenance, if you need to run a job, please make sure the end time will be before the start of the maintenance period.</p> <p>We always send out a reminder email (usually the Wednesday before) of the maintenance start date and then another email immediately after the work is complete and the clusters are available again. These emails go to the LCRC Users email list. All LCRC users are subscribed to this list by default.</p>"},{"location":"best-practices-and-policies/reservation-policy/","title":"Reservation Policy","text":"<p>While the LCRC batch queues are designed to handle the vast majority of work, we recognize that there are special circumstances that require exclusive use of a portion of our resources for a period of time, e.g., to meet an urgent deadline, to carry out certain kinds of benchmarks or conduct workshops. Often we can meet such needs by reserving a specific number of nodes for your project for a specific period of time.</p> <p>To set up a reservation send an email to support@lcrc.anl.gov with the name of the partition/cluster, number of nodes, desired start time, and duration (hours).  Based on the load on the partition/cluster at the time of the reservation request, an allocation decision will be made.  In case a reservation for the total duration and/or nodes requested by the PI cannot be made, a partial reservation might be granted.  </p> <ul> <li>Reservations must be requested at least 8 business days in advance and are subject to availability of resources.</li> <li>Reservations cannot be requested more than once per quarter per project.</li> <li>Typically, reservations can be for a maximum of 8,000 node hours (both on Bebop &amp; Improv). Larger evaluation requests will be evaluated on a case-by-case basis.</li> <li>Reservations create substantial perturbations to the scheduling of other jobs long before the reservation starts. Once a reservation is scheduled it cannot be rescheduled, and if you end up not needing or using it, the project will still be charged for the reservation time. It is like a non-refundable movie ticket.</li> <li>If a reservation is required to host a workshop with hands-on user participation, please let us know well in advance.  This will enable us to plan the reservation window(s) during the work-day(s) to ensure minimal disruption to the user community.</li> </ul>"},{"location":"best-practices-and-policies/shared-resource-policy/","title":"Shared Resource Policy","text":""},{"location":"best-practices-and-policies/shared-resource-policy/#use-of-login-nodes","title":"Use of Login Nodes","text":"<p>LCRC login nodes are primarily for managing files in the project and home directories, editing files, submitting/monitoring jobs in the queue and compiling short codes/applications. Please do not run jobs on any LCRC login nodes. Not only do they slow down the system for other users, but can also bring down the login node. Please use the cluster compute queues for testing and running production jobs and compiling large codes. The queues can be used in both interactive mode and batch mode.</p> <p>Login nodes are also set to throttle user processes that exceed certain CPU or memory thresholds automatically via cgroups. For code compilation requiring multiple CPUs or large amounts of memory, it is recommended to use a compute node. Refer to each cluster's hardware overview for more details.</p>"},{"location":"best-practices-and-policies/shared-resource-policy/#use-of-debugging-queues","title":"Use of Debugging Queues","text":"<p>Some LCRC clusters have debug queues. These queues are to be used only for debugging applications, testing the scaling/timing of a code/problem or checking to see if a new problem has been correctly set-up (proper input parameters, I/O file names etc). This queue is also extensively used by the LCRC staff to test new capabilities/codes, system performance, and address user issues. Debug queues on LCRC cluster are nodes with a maximum time-limit of 1 hour and often can be shared my multiple users. Please do not run hour-long production jobs on this queue. It is also recommended that users limit the maximum job size to 4 nodes whenever possible.</p>"},{"location":"best-practices-and-policies/ssh-policy/","title":"SSH Policy","text":"<p>This document explains the policies users must follow when creating, storing, and using SSH keys for accessing the LCRC systems.</p>"},{"location":"best-practices-and-policies/ssh-policy/#summary","title":"Summary","text":"<ul> <li>SSHv1 keys are not supported, therefore v1 keys are unusable.</li> <li>SSHv2 RSA keys are allowed.</li> <li>SSHv2 keys must contain at least 4096 bits.</li> <li>SSHv2 keys must have a strong passphrase (details below).</li> <li>Keys should be generated on a known secure machine.</li> <li>Private keys should not be stored on LCRC systems.</li> </ul>"},{"location":"best-practices-and-policies/ssh-policy/#explanation","title":"Explanation","text":"<p>The ability to crack SSHv2 keys depends directly on the type of key, the number of bits in the key, and the strength/quality and secrecy of the passphrase. The above guidelines are intended to minimize the risk of compromise if someone obtained a copy of your keys or was able to intercept your SSH session.</p>"},{"location":"best-practices-and-policies/ssh-policy/#ssh-passphrases","title":"SSH Passphrases","text":"<p>SSHv2 keys must have a strong passphrase that:</p> <ol> <li>Is NOT a word in any language</li> <li>Is NOT a proper noun/name, brand name, foreign name, or other name</li> <li>Is NOT a word or set of words obtainable by:<ul> <li>\"finger\" command (e.g. QWERTY),</li> <li>looking in your .plan, .project, or other public files,</li> <li>looking at any of your public web pages.</li> </ul> </li> <li>Is NOT a word followed by a number.</li> <li>Is NOT a reversed version of any of the above.</li> <li>Is NOT an address (e.g. 9700S.Cass).</li> <li>Is NOT derived from a single word (e.g. He77o).</li> <li>Is a long passphrase, must be longer than 8 characters. SSH passphrases can be made up of several words or character strings. Unlike traditional Unix passwords that are limited to 8 characters, these can and should be much longer. However, it should not be so long that you are unable to type it correctly multiple times.</li> <li> <p>Should contain mixed case letters, digits, and special characters.</p> </li> <li> <p>Should be kept secret and NOT written down anywhere.</p> </li> <li>Should NOT be used as a password anywhere else, or as passphrases to other SSH keys.</li> </ol> <p>Failure to comply with the strong passphrase guidelines may make your passphrase guessable by people who are resourceful in finding information about you, or crackable using commonly available cracking software.</p> <p>You should NOT use the passphrase to your LCRC SSH key(s) as a password on any other machines. If you share passwords or passphrases between resources and one resource is compromised and passwords or passphrases are stolen, they could be used to compromise LCRC.</p> <p>If you learn of a security compromise at a remote site where you have an account please notify support@lcrc.anl.gov.</p> <p>NEVER GIVE YOUR PASSPHRASE TO ANYONE! Never tell anyone your passphrase or password over the phone. Nobody from LCRC will ask for your passphrase or password over the phone (we can access your account without it, system administrators never need to know your passphrase or password). If someone calls you and asks for your passphrase or password, please report this by sending mail to support@lcrc.anl.gov. If you receive an email from someone requesting your passphrase or password (including support@lcrc.anl.gov and root), please inform us immediately.</p> <p>NEVER WRITE YOUR PASSPHRASE OR PASSWORD DOWN. Make your passphrase unique but something you can remember so you don\u2019t have to write it down. Having a longer passphrase can help you remember it. If the piece of paper you write your passphrase down on is stolen, your SSH keys could be compromised.</p>"},{"location":"best-practices-and-policies/ssh-policy/#storing-ssh-key-pairs","title":"Storing SSH Key Pairs","text":"<p>Protecting your ssh private keys is important:</p> <ul> <li>Set permissions so that only you have read/write access (i.e. <code>chmod 600 &lt;privatekeyfile&gt;</code> ). If you are a Cygwin user, please read the note about Cygwin Unix file permissions at the bottom of this page.</li> <li>Try to only have them on a single machine that is locked down very tightly (i.e. no remote access allowed, no sshd, ftpd, telnetd, etc running), firewall protected, up-to-date on all security patches, including kernel patches.</li> <li>Try not to have them on an NFS mounted file system.</li> </ul> <p>Public keys don\u2019t need to be protected:</p> <ul> <li>May be copied to other machines.</li> <li>May have permissions that allow others to read it.</li> <li>We recommend that the authorized_keys file have permissions of 600.</li> </ul> <p>Security of SSH keys depends on keeping both the private key and the passphrase secret. The best way to keep the private key secure is to store it on known secure machines like a personal laptop or workstation. When a machine is compromised the private keys on that machine are available to the hacker. It\u2019s very important to keep your private keys on as few machines as possible, to pick the most secure machines possible, and to avoid whenever possible storing them on machines and file-systems available to many users.</p> <p>If you wish to be even more secure, you can keep your keys on external media, such as a USB memory stick. Then when you wish to log onto a remote computer, mount the external media on your local system, add the key to your ssh-agent with a very short timeout (1 minute is reasonable), unmount the external media and open the connection to the remote system. This allows you get access to the remote system while keeping your private key virtually inaccessible to any remote hacker. For information on using ssh-agent, read the ssh-agent man page.</p>"},{"location":"best-practices-and-policies/ssh-policy/#using-ssh-key-pairs","title":"Using SSH Key Pairs","text":"<p>When you use a passphrased SSHv2 key the ssh client will prompt you for your passphrase. This passphrase is used on your local machine to decrypt your private key so it can be used to connect to the remote machine. The private key never leaves the client machine (in encrypted or decrypted form).</p> <p>For the remote machine to accept your ssh connection it must have your public key. Instructions for setting up your LCRC keys are available here.</p> <p>If you ssh many times and you wish to avoid typing in the passphrase every time, you can use an ssh-agent. An ssh-agent allows your client machine to keep a decrypted form of your ssh private key in memory for use when ssh'ing to multiple machines. For information on using ssh-agent, read the ssh-agent man page.</p> <p>You may use ssh-agent forwarding when connecting through one machine to another machine. But, because of security issues, you should only enable agent forwarding for connections where you will need it and shutdown the connection as soon as you are finished using it.</p>"},{"location":"data-management/lcrc-data-storage/","title":"LCRC Data Storage","text":""},{"location":"data-management/lcrc-data-storage/#storage-systems-access","title":"Storage Systems Access","text":"<p>On all of our clusters, users have access to a global home, project, and group space (if they belong to a group that has purchased additional storage). This means that files created from compute nodes on one cluster can be used for calculations on any of our other clusters. All storage systems use GPFS as the file system and certain filesystems are backed up nightly.</p>"},{"location":"data-management/lcrc-data-storage/#filesystem-quotas","title":"Filesystem Quotas","text":"Filesystem Location Soft Limit Hard Limit Home <code>/home/&lt;username&gt;</code> 100 GB 1 TB Project <code>/lcrc/project/&lt;project_name&gt;</code> 1+ TB 2+ TB Group <code>/lcrc/group/&lt;group_name&gt;</code> no quotas no quotas"},{"location":"data-management/lcrc-data-storage/#additional-storage-options","title":"Additional Storage Options","text":"<p>We also offer the ability for groups to purchase their own storage resources to be hosted with us. In doing so you get access to the storage space across all of our clusters (unless otherwise specified), and we take care of supporting the system, replacing parts, and when possible tuning the storage resources to fit your data model.</p> <p>Interested in more storage? Contact us at support@lcrc.anl.gov.</p>"},{"location":"data-management/lcrc-data-storage/#scratch-space","title":"Scratch Space","text":"<p>You also have access to scratch space on the compute nodes while you have a job running on the node.</p>"},{"location":"data-management/data-transfer/sftp-scp/","title":"SFTP and SCP","text":"<p>These standard utilities are available for local area transfers of small files; they are not recommended for use with large data transfers due to poor performance and excess resource utilization on the login nodes.</p> <p>See Globus for performing large data transfers.</p>"},{"location":"data-management/data-transfer/using-globus/","title":"Using Globus","text":"<ul> <li>Log in to Globus using your Argonne Domain Account credentials by selecting Argonne National Laboratory from the existing organizational list. Alternatively, you can sign up for and use your local Globus username and password.</li> <li>Select <code>File Manager</code> from the side bar.</li> <li>On the File Manager page, you can view and search the list of available endpoints by clicking the text field labeled <code>Collection</code>.<ul> <li>You can use the LCRC endpoint \"LCRC Improv DTN\" (as well as other sources or destinations).</li> <li>You can type letters into the box to filter endpoints.</li> </ul> </li> <li>Once you select the LCRC endpoint:</li> <li>You will be prompted with an \"Authentication/Consent Required\" page. Click \"Continue\".</li> <li>On the \"Identity Required\" page, select your <code>@anl.gov</code> identity from the list. You may need to authenticate here with your Argonne credentials.</li> <li>Next, click \"Allow\" to give consent for the Globus Web App to manage transfers and access data.</li> <li>You will see a listing of the contents of your home directory in LCRC by default. Double click on a directory to view its contents.</li> <li>You can change the Path to another LCRC directory on the shared filesystem that you have access to as needed.</li> <li>Select a file or directory and click on the highlighted <code>arrow button</code> to initiate the transfer.</li> </ul>"},{"location":"data-management/data-transfer/using-globus/#transferring-data-between-lcrc-and-your-machine","title":"Transferring Data Between LCRC and Your Machine","text":"<p>To transfer data between LCRC and your laptop or desktop, you can install Globus Connect Personal on your machine and access it via Globus. Globus Connect Personal is available as a one-click install for Mac, Linux, and Windows.</p> <ul> <li>Install Globus Connect Personal following the instructions for your operating system.</li> <li>Run Globus Connect Personal on your local machine. The Globus Connect Personal webpage can walk you through the setup instructions.</li> <li>You should now see your machine in the list of endpoints on Globus. You can select it to view the contents of your machine and transfer files to and from it as above.</li> </ul>"},{"location":"data-management/filesystem-and-storage/data-storage/","title":"Data Storage","text":""},{"location":"data-management/filesystem-and-storage/data-storage/#overview","title":"Overview","text":"<ul> <li>Users have access to a global home, project, and group space.</li> <li>Files created on one cluster can be used across all clusters.</li> <li>All storage systems use GPFS as the file system.</li> <li>Certain filesystems are backed up nightly.</li> </ul>"},{"location":"data-management/filesystem-and-storage/data-storage/#backup-storage","title":"Backup Storage","text":""},{"location":"data-management/filesystem-and-storage/data-storage/#disk-drives","title":"Disk Drives","text":"<ul> <li>Total Number of Drives Across All JBODs: 612 (6 JBODs x 102 Drives each)</li> <li>Drive Type: WDC HC530 SAS Enterprise Disk Drives</li> <li>Drive Capacity: 14TB each</li> <li>Uses ZFS for its the filesystem</li> </ul> <p>Maintenance and Data Integrity:</p> <ul> <li>Automated monthly scrubs are scheduled for each zpool. These scrubs are essential for maintaining data integrity and for early identification of potential issues.</li> </ul>"},{"location":"data-management/filesystem-and-storage/data-storage/#tape-storage","title":"Tape Storage","text":"<ul> <li>LCRC has roughly 760 tapes to which we backup and replicate data from the disk storage.</li> <li>We are currently running LTO9 tape technology.</li> </ul>"},{"location":"data-management/filesystem-and-storage/data-storage/#purchasing-resources","title":"Purchasing Resources","text":"<p>We offer the ability for groups to purchase their own storage resources to be hosted with us. In doing so you get access to the storage space across all of our clusters (unless otherwise specified), and we take care of supporting the system, replacing parts, and when possible tuning the storage resources to fit your data model.</p> <p>If you are interested in learning more about purchasing additional storage resources please contact us at support@lcrc.anl.gov</p> <p>You also have access to scratch space on the compute nodes while you have a job running on the node.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/","title":"Disk Quota Information","text":""},{"location":"data-management/filesystem-and-storage/disk-quota/#overview","title":"Overview","text":"<p>Quotas are enforced on home and project directories to manage storage resources effectively.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/#home-and-project-directory-quotas","title":"Home and Project Directory Quotas","text":"<ul> <li>Home Directories: Each user is allocated a standard quota of 100 GB.</li> <li>Project Directories: Projects are allocated a default of 1 TB, with the option to request increases.</li> </ul>"},{"location":"data-management/filesystem-and-storage/disk-quota/#quota-enforcement","title":"Quota Enforcement","text":"<ul> <li>Soft Limits: Users can temporarily exceed their allocated quotas to avoid disrupting running jobs.</li> <li>Grace Period: Users have a two-week period to manage and reduce their data usage back within quota limits after exceeding the soft limit.</li> <li>Hard Limits: Persistent excess use beyond the grace period will result in write restrictions, preventing new data from being saved until the usage is reduced.</li> </ul>"},{"location":"data-management/filesystem-and-storage/disk-quota/#quota-table","title":"Quota Table","text":"Filesystem Location Soft Limit Hard Limit Home <code>/home/&lt;username&gt;</code> 100 GB 1 TB Project <code>/lcrc/project/&lt;project_name&gt;</code> 1+ TB 2+ TB Group <code>/lcrc/group/&lt;group_name&gt;</code> No quotas No quotas"},{"location":"data-management/filesystem-and-storage/disk-quota/#checking-your-quota","title":"Checking Your Quota","text":"<p>To view your current quota usage, use the command <code>lcrc-quota</code>.</p> <pre><code>$ lcrc-quota\n\n----------------------------------------------------------------------------------------\nHome                          Current Usage   Space Avail    Quota Limit    Grace Time\n----------------------------------------------------------------------------------------\nUserX                         113 GB         -13 GB         100 GB         8 days\n----------------------------------------------------------------------------------------\nProject                       Current Usage   Space Avail    Quota Limit    Grace Time\n----------------------------------------------------------------------------------------\nImprovAcceptance                    0 GB        1024 GB        1024 GB\nlcrc-app-engr                   11231 GB        9248 GB       20480 GB\nmcnp_software                       1 GB        1023 GB        1024 GB\nsupport                          6442 GB        3781 GB       10240 GB\n</code></pre>"},{"location":"data-management/filesystem-and-storage/disk-quota/#requesting-additional-storage","title":"Requesting Additional Storage","text":"<p>Eligibility: Only available for project directories.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/#process","title":"Process","text":"<ol> <li>Visit https://accounts.lcrc.anl.gov</li> <li>Under <code>Owned</code> projects, select the project requiring more storage.</li> <li>Input the desired storage amount in TB in the <code>Storage (TB)</code> field.</li> <li>Provide a justification under <code>Storage Justification</code>.</li> <li>Save changes to submit your request for review.</li> </ol>"},{"location":"data-management/filesystem-and-storage/disk-quota/#over-quota-management","title":"Over-Quota Management","text":"<p>If your home directory is over quota, consider deleting unnecessary files or moving data to project or group directories.</p>"},{"location":"data-management/filesystem-and-storage/file-systems/","title":"File Systems","text":""},{"location":"data-management/filesystem-and-storage/file-systems/#home-project-and-group-disks","title":"Home, Project, and Group Disks","text":"<p>Your home, project, and group directories are located on separate GPFS filesystems that are shared by all nodes on the cluster. These filesystems are located on a raid array and are served by multiple file servers. This provides both a performance increase and protection against the filesystems being inaccessible. If one server goes down, the other servers can continue to serve the filesystems.</p>"},{"location":"data-management/filesystem-and-storage/file-systems/#pros","title":"Pros","text":"<ul> <li>Global namespace</li> <li>Multi-TB filesystem</li> <li>Large file support (&gt; 2GB)</li> <li>Backed up</li> <li>Raid protection</li> <li>Stable hardware</li> <li>Native InfiniBand support</li> </ul>"},{"location":"data-management/filesystem-and-storage/file-systems/#cons","title":"Cons","text":"<ul> <li>Moderate performance</li> </ul>"},{"location":"data-management/filesystem-and-storage/file-systems/#local-and-global-scratch-disks","title":"Local and Global Scratch Disks","text":""},{"location":"data-management/filesystem-and-storage/file-systems/#local","title":"Local","text":"<p>If you need a place to put temporary files that don\u2019t need to be accessed by other nodes, we recommend that you put them into the local scratch disk on the nodes during job runs. All jobs create a job specific directory with local storage which can be referenced from your job submission script using the /scratch directory. The normal publicly available nodes offer 15 GB of temporary scratch space. Diskfull Bebop nodes also house a 4TB disk on each node. Note that these spaces aren\u2019t backed up and the space will be cleared out on job end!</p>"},{"location":"data-management/filesystem-and-storage/file-systems/#local-scratch-disk-pros","title":"Local Scratch Disk Pros","text":"<ul> <li>Fast access times</li> <li>Large file support (&gt; 2GB)</li> </ul>"},{"location":"data-management/filesystem-and-storage/file-systems/#local-scratch-disk-cons","title":"Local Scratch Disk Cons","text":"<ul> <li>Unique to each node; not shared between nodes</li> <li>GB filesystem</li> <li>Not backed up</li> <li>Cleared out at the end of your job</li> <li>No raid protection</li> </ul>"},{"location":"data-management/filesystem-and-storage/file-systems/#global","title":"Global","text":"<p>LCRC also has a global scratch space located at /lcrc/globalscratch. This space is a GPFS filesystem that is several TBs in size (the size may change over time). This space is shared to all LCRC nodes, unlike the local scratch space. Because this is a GPFS filesystem, IO will not be as fast.</p> <p>NOTE: This global scratch space may be cleaned up during our maintenance days or at other intervals and all files deleted in this space with or without notice. This space is not intended for long term storage and is not backed up in any way. Files deleted either accidentally or on purpose are permanently deleted.</p>"},{"location":"data-management/filesystem-and-storage/file-systems/#global-scratch-disk-pros","title":"Global Scratch Disk Pros","text":"<ul> <li>Shared between nodes</li> <li>Very large capacity</li> </ul>"},{"location":"data-management/filesystem-and-storage/file-systems/#global-scratch-disk-cons","title":"Global Scratch Disk Cons","text":"<ul> <li>Slower access time</li> <li>Not backed up</li> <li>Cleared out with or without notice</li> <li>No raid protection</li> </ul>"},{"location":"improv/getting-started-improv/","title":"Getting Started on Improv","text":""},{"location":"improv/getting-started-improv/#accessing-improv","title":"Accessing Improv","text":"<p>Due to updated security requirements, direct SSH access to Improv is no longer permitted. All inbound access must now go through the CELS login nodes using a jump host configuration.</p> <p>You cannot SSH directly into the CELS login nodes. Instead, connect using the command below (replacing <code>&lt;username&gt;</code> and <code>&lt;ssh_private_key&gt;</code> accordingly):</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@improv.lcrc.anl.gov\n</code></pre> <p>Alternatively, you can simplify future connections by adding the following block to your <code>~/.ssh/config</code>:</p> <pre><code>Host logins.lcrc.anl.gov\n  HostName logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n\nHost improv.lcrc.anl.gov improv\n  HostName improv.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User &lt;username&gt;\n  IdentityFile ~/.ssh/&lt;ssh_private_key&gt;\n</code></pre> <p>After configuring this, you can connect with either:</p> <pre><code>ssh improv.lcrc.anl.gov\n</code></pre> <p>or simply:</p> <pre><code>ssh improv\n</code></pre> <p>Note: The logins.lcrc.anl.gov alias is provided as part of LCRC's integration with CELS login infrastructure.</p>"},{"location":"improv/getting-started-improv/#system-architecture","title":"System Architecture","text":"<p>For a detailed overview of the Improv system, including the compute node architecture, refer to the Hardware Overview page.</p>"},{"location":"improv/getting-started-improv/#job-execution","title":"Job Execution","text":"<p>For information on how to run jobs on Improv, refer to the Running Jobs page.</p>"},{"location":"improv/hardware-overview-improv/","title":"Improv Hardware Overview","text":"<p>Improv has 825 dual-socket compute nodes with AMD 7713 64-core processors (2.0 GHz) (or 128 cores per node) and 256 GB DDR4 memory. 68 nodes have 6TB NVMe SSD, and 12 of those have 1024 GB DDR4, instead of 256 GB. The high-performance interconnect is Nvidia/Mellanox HDR200 (14 core, 35 edge switches). There are 12 HDR200 connections to LCRC\u2019s existing data storage system so you will have access to all of the same files between LCRC clusters.</p>"},{"location":"improv/hardware-overview-improv/#improv-compute-nodes","title":"Improv Compute Nodes","text":"Improv Compute Description Per Node Aggregate Processor (Note 1) 2.0 GHz 7713 2 Sockets 1,650 Cores/Threads 64 Cores/1 Thread per core 128 105,600/105,600 Memory DDR4 256 GiB (Nodes i001-814)1 TiB (Nodes i815-825) 219,648 GiB Local SSD 1 TB (Nodes i001-375, i444-813)5.9 TB (Nodes i376-443, i814-825) 1 1,217 TB <p>Note 1 L1d Cache (Level 1 Data Cache): 32 KB, L1i Cache (Level 1 Instruction Cache): 32 KB, L2 Cache: 512 KB, L3 Cache: 32,768 KB (or 32 MB)</p>"},{"location":"improv/hardware-overview-improv/#improv-login-nodes","title":"Improv Login Nodes","text":"<p>There are four login nodes available to users for editing code, building code, submitting/monitoring jobs, checking usage (<code>sbank</code>), etc. Their full hostnames are <code>iloginN.lcrc.anl.gov</code> for <code>N</code> equal to <code>1</code> through <code>4</code>.  The login nodes hardware is identical to the compute nodes. The various compilers and libraries are present on the logins, so most users should be able to build their code. All users share the same login nodes so please be courteous and respectful of your fellow users. For example, please do not run computationally or IO intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.</p> <p>Individual user processes on the login nodes will be throttled temporarily for those that exceed 16 CPUs and 16GB of RAM.</p>"},{"location":"improv/running-jobs-improv/","title":"Running Jobs on Improv","text":""},{"location":"improv/running-jobs-improv/#quickstart","title":"Quickstart","text":"<p>Presented below are fundamental commands essential for day-to-day use by most LCRC users on Improv. Comprehensive guides are available in other sections linked within our documentation.</p> <p>Check your Current Allocation Balance(s):</p> <pre><code>sbank-list-allocations -p &lt;project_name&gt;\n</code></pre> <p>Check your Filesystem Quota(s):</p> <pre><code>lcrc-quota\n</code></pre> <p>Submit a Batch Job: </p> <pre><code>qsub -A &lt;project&gt; &lt;your job script&gt;\n</code></pre> <p>List All Jobs:</p> <pre><code>qstat\n</code></pre> <p>Delete a Job:</p> <pre><code>qdel &lt;jobid&gt;\n</code></pre>"},{"location":"improv/running-jobs-improv/#job-scheduling-system","title":"Job Scheduling System","text":"<p>Improv's job scheduling system is characterized by:</p> <ul> <li>Uses PBS Pro</li> <li>Uses the <code>sbank</code> accounting system</li> <li>Allocations are calculated in node hours</li> </ul>"},{"location":"improv/running-jobs-improv/#queues","title":"Queues","text":"<p>Improv currently enforces the following limits on publicly available queues:</p> <ul> <li>15 Running Jobs per user.</li> <li>100 Queued Jobs per user.</li> <li>40 Running Nodes per user.</li> <li>60 Running Nodes per project.</li> <li>3 Days (72 Hours) Maximum Walltime.</li> <li>1 Hour Default Walltime if not specified.</li> <li>compute (Standard Compute Nodes) is the default queue.</li> </ul> <p>Use the <code>-q</code> option with <code>qsub</code> to select a queue.</p> Improv Queue Name Description Number of Nodes CPU Type Cores Per Node Memory Per Node Local Scratch Disk Max Walltime compute Standard Compute Nodes 805 2x AMD EPYC 7713 64-Core Processor 128 256GB DDR4 960GB (6TB bigdata Nodes) 72 Hours (3 Days) bigmem Large Memory Compute Nodes 12 2x AMD EPYC 7713 64-Core Processor 128 1TB DDR4 6TB 72 Hours (3 Days) debug Reduced Walltime Compute Nodes 8 2x AMD EPYC 7713 64-Core Processor 128 256GB DDR4 960GB 1 Hour backfill Idle Compute Nodes 825 2x AMD EPYC 7713 64-Core Processor 128 256GB or 1TB DDR4 960GB or 6TB 4 Hours <p>The compute queue also has 68 nodes with a 6TB local NVMe scratch disk. You can request these directly by adding <code>bigdata=true</code> to your PBS select statement. For example:</p> <pre><code>#PBS -l select=8:ncpus=128:mpiprocs=128:bigdata=true\n</code></pre>"},{"location":"improv/running-jobs-improv/#backfill-queue","title":"Backfill Queue","text":"<p>The backfill queue is used to improve the overall efficiency of the cluster by utilizing idle resources that would otherwise remain unused. Only jobs that ran out of hours may use the backfill queue, and the maximum wall-time is 4 hours. Users can submit jobs to the backfill queue by specifying it as the target queue in the PBS select statement. For example:</p> <pre><code>#PBS -q backfill\n</code></pre> <p>An example for interactive jobs:</p> <pre><code>qsub -q backfill -l select=1:ncpus=128:mpiprocs=128 -l walltime=15:00 -A support -I\n</code></pre>"},{"location":"improv/running-jobs-improv/#running-mpi-applications","title":"Running MPI Applications","text":"<p>OpenMPI is the recommended MPI for use on Improv.</p> <p>Here are some parameters that might be useful:</p> <p><code>-np &lt;processes&gt;</code>: This specifies the number of processes to launch. It should match the number of processors or cores you've requested in your job script. If you plan to use all the cores on each node you are allocated, this is not necessary in a submission script. The <code>#PBS -l select=&lt;# of nodes&gt;:ncpus=128:mpiprocs=128</code> script header takes care of this.</p> <p><code>--display-map</code>: This displays a map showing where MPI processes are running.</p> <p><code>--report-bindings</code>: This reports how MPI processes are bound to cores or sockets.</p> <p>For the most accurate and detailed information, please refer to the OpenMPI documentation.</p> <pre><code>#!/bin/bash -l\n# UG Section 2.5, page UG-24 Job Submission Options\n# Note: Command line switches will override values in this file.\n\n# ----------------- PBS Directives ----------------- #\n# These options are mandatory in LCRC; qsub will fail without them.\n\n# select: number of nodes. Adjust these values as per your job's requirement. In the below example, 4 nodes are requested.\n# ncpus: number of cores per node. (use 128 unless you have a reason otherwise)\n# mpiprocs: number of MPI processes (use the same value as ncpus unless you have a reason otherwise ).\n# walltime: a limit on the total time from the start to the completion of a job\n#PBS -A &lt;project_name&gt;\n#PBS -l select=4:ncpus=128:mpiprocs=128\n#PBS -l walltime=HH:MM:SS\n\n# Queue for the job submission\n#PBS -q &lt;queue&gt;\n\n# Job name (first 15 characters are displayed in qstat)\n#PBS -N &lt;job_name&gt;\n\n# Output options: 'oe' to merge stdout/stderr into stdout, 'eo' for stderr, 'n' to not merge.\n#PBS -j n\n\n# Email notifications: 'b' at begin, 'e' at end, 'a' on abort. Remove 'n' for no emails.\n#PBS -m be\n#PBS -M &lt;your_email_address&gt;\n\n# --------------- Script Execution Part --------------- #\n# The following is an example setup for an MPI job.\n\necho \"Working directory: $PBS_O_WORKDIR\"\ncd $PBS_O_WORKDIR\n\necho \"Job ID: $PBS_JOBID\"\necho \"Running on host: $(hostname)\"\necho \"Running on nodes: $(cat $PBS_NODEFILE)\"\n\n# Loading GCC and MPI modules, and verifying the environment.\nmodule load gcc openmpi\nmodule list\nwhich mpirun\n\n# Run the MPI program\nmpirun ./hello_mpi\n</code></pre> <p>Important things to note:</p> <ul> <li>PBS Pro on Improv is currently not configured to allow sharing nodes. When have a node allocated to you, you receive the ENTIRE node. Ensure that you use all of your allocated nodes' resources unless you have a reason not to.</li> <li>More information about running jobs on PBS can be found on our Running Jobs on PBS Clusters page.</li> </ul>"},{"location":"improv/running-jobs-improv/#job-submission-examples","title":"Job Submission Examples","text":""},{"location":"improv/running-jobs-improv/#example-qsub-job-submission","title":"Example <code>qsub</code> Job Submission","text":""},{"location":"improv/running-jobs-improv/#example-interactive-job-submission","title":"Example Interactive Job Submission","text":""},{"location":"running-jobs-at-lcrc/overview/","title":"Running Jobs at LCRC","text":"<p>LCRC has three generally accessible high-performance computing clusters: Bebop, Swing, and Improv. These clusters are designed to cater to a wide range of computational needs and research projects.</p> <p>LCRC employs PBS Pro for job scheduling. For detailed guidelines on utilizing these systems, please refer to the following resources:</p> <ul> <li>Running Jobs on PBS Pro Clusters</li> </ul>"},{"location":"running-jobs-at-lcrc/pbs-pro/","title":"Running Jobs on PBS Clusters","text":"<p>This document complements the information provided on the Improv, Bebop, and Swing pages, forming a comprehensive resource for running jobs effectively. Both pages should be referenced for a complete understanding.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#obtaining-and-managing-compute-resources","title":"Obtaining and Managing Compute Resources","text":""},{"location":"running-jobs-at-lcrc/pbs-pro/#definitions-and-notes","title":"Definitions and Notes","text":"<p><code>chunk</code>: A set of resources allocated as a unit to a job. Specified inside a selection directive. All parts of a chunk come from the same host. In a typical MPI (Message-Passing Interface) job, there is one chunk per MPI process.</p> <p><code>vnode</code>: A virtual node, or vnode, is an abstract object representing a host or a set of resources which form a usable part of an execution host. This could be an entire host, or a nodeboard or a blade. A single host can be made up of multiple vnodes. Each vnode can be managed and scheduled independently. Each vnode in a complex must have a unique name. Vnodes on a host can share resources, such as node-locked licenses. PBS operates on vnodes. A vnode on Improv and Bebop represents an entire host.</p> <p><code>ncpus</code>: Number of resources available to execute a program. Users are encouraged to use all of the cores on the node and pack nodes with multiple jobs when possible.</p> <p><code>ngpus</code>: Only relevant on Swing; Requests the specified number of GPUs. Users can only request 1, 2, 4, or 8 at a time.</p> <p><code>job</code>: A job equates to a qsub. A set of resources allocated to you for a period of time. Your will execute one or more tasks on those resources during your job.</p> <p><code>task</code>: A single execution on the resources of your job, often an mpirun invocation. You may run one task or many tasks during your job. You may run tasks sequentially or divide your resources up and run several tasks concurrently. Also sometimes referred to as job steps.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#quick-start","title":"Quick Start","text":"<p>If you are an LCRC user and are familiar with Slurm, you will find the PBS Pro commands very similar though the options to qsub are quite different. We have added a handy conversion \"cheat sheet\" here. Here are the \u201cBig Four\u201d commands you will use with PBS Pro:</p> <ol> <li><code>qsub</code>: request resources (generally compute nodes) to run your job and start your script/executable on the head node. Here is the minimal qsub allowed at the LCRC:<ul> <li><code>qsub -A &lt;project&gt; -l select=&lt;# of nodes&gt;,walltime=HH:MM:SS &lt;your job script&gt;</code></li> <li>The <code>-A</code> and walltime options are mandatory. You will receive errors if they are not specified.</li> <li>We automatically add <code>-l place=scatter</code> for you so that each of your chunks (<code>&lt;# of nodes&gt;</code>) gets its own vnode.</li> <li><code>-q &lt;queue_name&gt;</code> will place your job on the correct queue depending on the node type you want. The compute queue is the default on Improv.</li> <li>If you want to run an executable rather than a script replace <code>&lt;your jobs script&gt;</code> in the example above with <code>-- &lt;your executable&gt;</code> (that is dash dash)</li> </ul> </li> <li><code>pbsq</code>: a user-friendly filter for <code>qstat</code> to view the status of jobs and queues on the cluster.</li> <li><code>qalter</code>: update your request for resources<ul> <li>Just like <code>qsub</code>, just add a jobid at the end. Only works before the job starts;</li> <li>If you want to change the walltime to 30 minutes: <code>qalter -l walltime=30:00:00 &lt;jobid&gt;</code></li> </ul> </li> <li><code>qdel</code>: cancel a job that you don\u2019t need. This will also kill a running job.<ul> <li><code>qdel &lt;jobid&gt;</code></li> </ul> </li> </ol> <p>Note: The page numbers in the PBS guides are unique. If you search for the specified page number it will take you directly to the relevant page.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qsub-submit-a-job-to-run","title":"qsub: Submit a job to run","text":"<p>At the LCRC, your qsub will likely use the following parameters:</p> <p><code>qsub -A &lt;project&gt; -l select=&lt;#&gt;,walltime=HH:MM:SS &lt;your job script&gt;</code></p> <p>Where:</p> <ul> <li><code>&lt;project&gt;</code> is the project name associated with your allocation. What you check the balance of with the <code>sbank</code> command. This is a mandatory option at the LCRC. If you don\u2019t include it you will get <code>qsub: Account_Name is required to be set</code>.</li> <li><code>walltime=HH:MM:SS</code> specifying a wall time is mandatory at the LCRC. Jobs on Improv can run up to 72 hours maximum.</li> <li><code>&lt;your job script&gt;</code>: For options that won\u2019t change, you do have the option of taking things off the command line and putting them in your job script. For instance the above command line could be simplified to <code>qsub -l select=&lt;#&gt; &lt;your job script&gt;</code> if you added the following to the top (the PBS directives have to be before any executable line) of your job script:</li> </ul> <pre><code>#PBS -A &lt;project&gt;\n#PBS -l walltime=HH:MM:SS\n</code></pre> <p>Also note that if you want to run an executable directly rather than a script you use two dashes and the executable name in place of your script name like this: <code>-- /usr/bin/sleep 600</code></p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#resource-selection-and-job-placement","title":"Resource Selection and Job Placement","text":"<p>Resources come in two flavors:</p> <ul> <li>Job Wide: Walltime is the most common example of a job wide resource. You use the <code>-l</code> option to specify job wide resources, i.e. <code>-l walltime=06:00:00</code>. All the resources in the job have the same walltime.</li> <li><code>-l &lt;resource name&gt;=&lt;value&gt;[,&lt;resource name&gt;=&lt;value&gt; ...]</code></li> <li>Chunks: (see the definition above) This is how you describe what your needs are to run your job. You do this with the <code>-l select=</code> syntax. In the LCRC, we do whole node scheduling. This means you can typically get away with the very simple <code>-l select=4</code> which will give you 4 nodes with all of the available cpus.</li> <li><code>&lt;resource name&gt;=&lt;value&gt;[:&lt;resource name&gt;=&lt;value&gt; ...]</code></li> </ul> <p>You can also tell PBS how you want the chunks distributed across the physical hardware. You do that via the <code>-l place</code> option (scatter is our default):</p> <ul> <li><code>-l place=[&lt;arrangement&gt;][: &lt;sharing&gt; ][: &lt;grouping&gt;]</code> where</li> <li>arrangement is one of <code>free | pack | scatter</code></li> <li>unless you have a specific reason to do otherwise, you probably want to set this to scatter, otherwise you may not get what you expect. For instance on a host with ncpus=128, if you requested -l select=8:ncpus=8:mpiprocs=8 you could end up with all of our chunks on one node.</li> <li><code>free</code> means PBS can distribute them as it sees fit</li> <li><code>pack</code> means all chunks from one host. Note that this is not the minimum number of hosts, it is one host. If the chunks can\u2019t fit on one host, the qsub will fail.</li> <li><code>scatter</code> means take only one chunk from any given host.</li> </ul> <p>Here is a heavily commented sample PBS submission script that shows some more of the options, but remember that the PBS manuals referenced at the bottom of this page are the ultimate resource. If you create a file named hello.pbs for example, you can add:</p> <pre><code>#!/bin/bash -l\n# Add another # at the beginning of the line to comment out a line\n# NOTE: adding a switch to the command line will override values in this file.\n\n# These options are MANDATORY in LCRC; Your qsub will fail if you don't provide them.\n# Adjust the number of mpiprocs as needed by each system!\n#PBS -A &lt;project_name&gt;\n#PBS -l select=4:mpiprocs=128\n#PBS -l walltime=HH:MM:SS\n\n# Highly recommended\n# The first 15 characters of the job name are displayed in the qstat output:\n#PBS -N &lt;job_name&gt;\n\n# If you want to merge stdout and stderr, use the -j option\n# oe=merge stdout/stderr to stdout, eo=merge stderr/stdout to stderr, n=don't merge\n#PBS -j n\n\n# Controlling email notifications\n# When to send email b=job begin, e=job end, a=job abort, j=subjobs (job arrays), n=no mail\n#PBS -m be\n#PBS -M &lt;your_email_address&gt;\n\n# The rest is an example of how an MPI job might be set up\necho Working directory is $PBS_O_WORKDIR\ncd $PBS_O_WORKDIR\n\necho Jobid: $PBS_JOBID\necho Running on host `hostname`\necho Running on nodes `cat $PBS_NODEFILE`\n\nmodule load gcc openmpi    # Load a GCC and MPI module\nmodule list                # Print all loaded modules\nwhich mpirun               # Show which mpirun executable we are using\nmpirun ./hello_mpi         # Run a script\n</code></pre> <p>You would be able to submit the above script with:</p> <p><code>qsub hello.pbs</code></p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qsub-example","title":"qsub example","text":"<p>If you don\u2019t want to use a script, you could submit via the command line as well. For example:</p> <p><code>qsub -A &lt;project_name&gt; -l select=4:mpiprocs=128 -l walltime=30:00 -- a.out</code></p> <ul> <li>run a.out on 4 chunks with a walltime of 30 minutes ; charge project_name;</li> <li>run on 128 CPUs (ncpus) per node. On Improv by default, we allocate 128 cpus per node. Set ncpus if you want less. All jobs will be charged a whole node no matter how many cpus are requested.</li> <li>Allocate 128 MPI slots (mpiprocs) per node. Note: When using MPI, you must specify mpiprocs. We recommend it to be the same as ncpus.</li> <li>Since we allocate full nodes on Improv, 4 chunks will be 4 nodes. If we shared nodes, that would be 4 threads.</li> <li>use the <code>--</code> (dash dash) syntax when directly running an executable.</li> </ul>"},{"location":"running-jobs-at-lcrc/pbs-pro/#pbsq-a-user-friendly-filter-for-qstat","title":"pbsq: A user-friendly filter for qstat","text":"<p><code>pbsq</code> is a user-friendly filter for <code>qstat</code> to view the status of jobs and queues on the cluster. It provides a more user-friendly interface for <code>qstat</code> by providing a more intuitive way to view job and queue status.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#pbsq-basic-usage","title":"pbsq basic usage","text":"<p>Query all jobs that are running and queued:</p> <p><code>pbsq</code></p> <p>Query all jobs that belong to a project:</p> <p><code>pbsq -f &lt;project_name&gt;</code></p> <p>Query all jobs that belong to a user:</p> <p><code>pbsq -f &lt;user_name&gt;</code></p> <p>Use <code>pbsq -h</code> to see the help menu and other options.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qstat-query-the-status-of-jobsqueues","title":"qstat: Query the status of jobs/queues","text":"<p>The <code>qstat</code> command lists jobs on the system, showing their status, user, and other details. You can specify job IDs for detailed information about specific jobs.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qstat-basic-usage","title":"qstat basic usage","text":"<p><code>qstat</code>: Lists all jobs with basic details.</p> <p><code>qstat [jobID]</code>: Displays information for specific jobs.</p> <p>Options for expanded information:</p> <p><code>-w</code>: Expands the width of the output to reduce truncation.</p> <p><code>-was1</code>: Shows nodes, tasks, requested walltime, and comments in a single line.</p> <p><code>-wan</code>: Provides the list of nodes used.</p> <p><code>-T</code>: Estimates the start time for the job (only for the next expected jobs).</p> <p><code>-f</code>: Provides comprehensive details about a job.</p> <p><code>-x</code>: Shows finished jobs (history retained for one week) along with comments.</p> <p>The comment field is crucial for understanding job status or issues. It's often the first place to check when troubleshooting job-related queries in PBS.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qalter-alter-a-queued-job","title":"qalter: Alter a queued job","text":"<p>Basically takes the same options as <code>qsub</code>; Say you typoed and set the walltime to 300 minutes instead of 30 minutes. You could fix it (if the job had not started running) by doing <code>qalter -l walltime=30:00 &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code> The new value overwrites any previous value.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qdel-delete-a-queued-or-running-job","title":"qdel: Delete a queued or running job","text":"<p><code>qdel &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qholdqrls-place-release-a-user-hold-on-a-job","title":"qhold,qrls: Place / release a user hold on a job","text":"<p><code>[qhold | qrls] &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qselect-query-jobids-for-use-in-commands","title":"qselect: Query jobids for use in commands","text":"<p><code>qdel $(qselect -N test1)</code> will delete all the jobs that had the job name set to test1.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qmsg-write-a-message-into-a-jobs-output-file","title":"qmsg: Write a message into a jobs output file","text":"<p><code>qmsg -E -O \"This is the message\" &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></p> <p><code>-E</code> writes it to standard error, <code>-O</code> writes it to standard out</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#qsig-send-a-signal-to-a-job","title":"qsig: Send a signal to a job","text":"<pre><code>qsig -s &lt;signal&gt; &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]\n</code></pre> <p>If you don\u2019t specify a signal, <code>SIGTERM</code> is sent.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#pbsnodes-get-information-about-the-current-state-of-nodes","title":"pbsnodes: Get information about the current state of nodes","text":"<p>This is more for admins, but it can tell you more about the nodes themselves.</p> <p><code>pbsnodes &lt;node name&gt;</code>: Everything there is to know about a node</p> <p><code>pbsnodes -avSj</code>: A nice table to see what is free and in use</p> <p><code>pbsnodes -l</code>: (lowercase l) see which nodes are down. The comment often indicates why it is down</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#job-priority","title":"Job Priority","text":"<p>In PBS it is not easy to see a priority order for which jobs will run next. The best way is to use the <code>-T</code> option on <code>qsub</code> and look at the estimated start times. LCRC runs a custom scheduler algorithm, but in general, the job priority in the queue is based on several criteria:</p> <ol> <li>positive balance of your project</li> <li>size (in nodes) of the job, larger jobs receive higher priority</li> <li>job duration: shorter duration jobs will accumulate priority more quickly, so it is best to specify the job run time as accurately as possible</li> </ol>"},{"location":"running-jobs-at-lcrc/pbs-pro/#general-pbs-example-scriptscommands","title":"General PBS Example Scripts/Commands","text":""},{"location":"running-jobs-at-lcrc/pbs-pro/#submitting-an-interactive-job","title":"Submitting an Interactive Job","text":"<p>Here is how to submit an interactive job to, for example, edit/build/test an application:</p> <pre><code>qsub -I -A &lt;PROJECT_NAME&gt; -l select=1:ncpus=128:mpiprocs=128,walltime=01:00:00 -q compute\n</code></pre> <p>This command requests 1 node for a period of 1 hour in the compute queue. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. Remember to replace <code>&lt;PROJECT_NAME&gt;</code> with a valid LCRC project.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#submitting-a-pbs-array-job","title":"Submitting a PBS Array Job","text":"<pre><code>#!/bin/bash\n\n###### Tells PBS the job name\n#PBS -N array_example\n###### Tells PBS to run on 1 node with 128 cpus\n#PBS -l select=1:ncpus=128:mpiprocs=128\n###### Tells PBS the walltime (Max 72 hours)\n#PBS -l walltime=00:05:00\n###### Tells PBS the project to charge (Replace with a valid project)\n#PBS -A &lt;PROJECT_NAME&gt;\n###### Tells PBS to run 5 subjobs (Required to run in an array)\n#PBS -J 1-5\n###### Tells PBS to rerun the job (Rquired to run in an array)\n#PBS -r y\n\ncd $PBS_O_WORKDIR\necho \"Running subjob $PBS_ARRAY_INDEX\"\n\n# Create a subjob-specific directory\nmkdir -p subjob_${PBS_ARRAY_INDEX}\ncd subjob_${PBS_ARRAY_INDEX}\n\n# Run a command unique to each subjob\necho \"This is subjob ${PBS_ARRAY_INDEX}\" &gt; output_${PBS_ARRAY_INDEX}.txt\n\n# Sleep for a different amount of time based on the subjob index\nsleep ${PBS_ARRAY_INDEX}\n\necho \"Subjob $PBS_ARRAY_INDEX completed\"\n</code></pre> <p>The <code>pbsq</code> command subsequently shows the status of the job array.</p> <pre><code>$ pbsq\n138617[].imgt1    user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  B      compute  array_example     Job Array Began at Thu Mar 21 at 12:02\n138617[1].imgt1   user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  E      compute  array_example     i475\n138617[2].imgt1   user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  E      compute  array_example     i730\n138617[3].imgt1   user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  E      compute  array_example     i799\n138617[4].imgt1   user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  E      compute  array_example     i285\n138617[5].imgt1   user1             support               00:05:00    00:00:04  n/a       00:00:06       00:04:54      1  E      compute  array_example     i286\n</code></pre> <p>If you want to increase the number of nodes per subjob, you can increase the <code>select</code> value in <code>#PBS -l select=1:ncpus=128</code> to be equal to the number of nodes you want per subjob.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#running-multiple-mpi-applications-on-a-node","title":"Running Multiple MPI Applications on a Node","text":"<p>Multiple applications can be run simultaneously on a node by launching several mpirun commands and backgrounding them. For performance, it will likely be necessary to ensure that each application runs on a distinct set of CPU resources.</p> <pre><code>#!/bin/bash\n\n###### Tells PBS the job name\n#PBS -N packing_example\n###### Tells PBS to run on 1 node with 128 cpus\n#PBS -l select=1:ncpus=128:mpiprocs=128\n###### Tells PBS the walltime (Max 72 hours)\n#PBS -l walltime=00:05:00\n###### Tells PBS the project to charge (Replace with a valid project)\n#PBS -A &lt;PROJECT_NAME&gt;\n\ncd $PBS_O_WORKDIR\n\nexport range=$(eval echo {0..31} | xargs | sed -e 's/ /,/g\u2019)\nmpirun \u2013map-by pe-list:${range}:ordered \u2013np 32 a.out &amp;\n\nexport range=$(eval echo {32..95} | xargs | sed -e 's/ /,/g\u2019)\nmpirun \u2013map-by pe-list:${range}:ordered \u2013np 64 b.out &amp;\n\nexport range=$(eval echo {96..111} | xargs | sed -e 's/ /,/g\u2019)\nmpirun \u2013map-by pe-list:${range}:ordered \u2013np 16 c.out &amp;\n\nwait\n</code></pre> <ul> <li>Put each MPI tasks in the background with \"&amp;\".</li> <li>Use mpirun placement options to specifically place them on certain cores, to avoid oversubscription on some cores. A good practice would be to run each command in its own directory.</li> <li>Add <code>\u2013report-bindings</code> to see what is happening.</li> <li>You must use <code>wait</code> command.</li> </ul>"},{"location":"running-jobs-at-lcrc/pbs-pro/#troubleshooting-common-errors","title":"Troubleshooting / Common Errors","text":"<p>If you receive a <code>qsub: Job rejected by all possible destinations error</code>, then check your submission parameters. The issue is most likely that your walltime or node count do not fall within the ranges listed above for the production execution queues. Please see the table above for limits on production queue job sizes.</p> <p>NOTE: For batch submissions, if the parameters within your submission script do not meet the parameters of any of the above queues you might not receive the \u201cJob submission\u201d error on the command line at all. This can happen because your job is in waiting in a routing queue and has not yet reached the execution queues. In this case you will receive a jobid back and qsub will exit, however when the proposed job is routed, it will be rejected from the execution queues. In that case, the job will be deleted from the system and will not show up in the job history for that system. If you run a <code>qstat</code> on the jobid, it will return <code>qstat: Unknown Job Id &lt;jobid&gt;</code>.</p>"},{"location":"running-jobs-at-lcrc/pbs-pro/#documentation-and-tools","title":"Documentation and Tools","text":"<ul> <li>The PBS \u201cBigBook\u201d: This is really excellent. We highly suggest you download it and search through it when you have questions. However, it is big at about 2000 pages / 40MB and contains a bunch of stuff you don\u2019t really need, so you can also download the guides separately here:</li> <li>The PBS User Guide: This is the user guide.</li> <li>The PBS Reference Guide: This is the Reference Guide. It shows every option and gives you details on how to format various elements on the command line.</li> </ul>"},{"location":"swing/getting-started-swing/","title":"Getting Started on Swing","text":""},{"location":"swing/getting-started-swing/#accessing-swing","title":"Accessing Swing","text":"<p>Due to updated security requirements, direct SSH access to Swing is no longer permitted. All inbound access must now go through the CELS login nodes using a jump host configuration.</p> <p>You cannot SSH directly into the CELS login nodes. Instead, connect using the command below (replacing <code>&lt;username&gt;</code> and <code>&lt;ssh_private_key&gt;</code> accordingly):</p> <pre><code>ssh -o ProxyCommand=\"ssh -i ~/.ssh/&lt;ssh_private_key&gt; -W %h:%p &lt;username&gt;@logins.lcrc.anl.gov\" -i ~/.ssh/&lt;ssh_private_key&gt; &lt;username&gt;@swing.lcrc.anl.gov\n</code></pre> <p>Alternatively, you can simplify future connections by adding the following block to your <code>~/.ssh/config</code>:</p> <pre><code>Host logins.lcrc.anl.gov\n  HostName logins.lcrc.anl.gov\n  User username\n  IdentityFile ~/.ssh/id_rsa\n\nHost swing.lcrc.anl.gov swing\n  HostName swing.lcrc.anl.gov\n  ProxyJump logins.lcrc.anl.gov\n  User username\n  IdentityFile ~/.ssh/id_rsa\n</code></pre> <p>After configuring this, you can connect with either:</p> <p><code>ssh swing.lcrc.anl.gov</code></p> <p>or simply:</p> <p><code>ssh swing</code></p> <p>Note: The logins.lcrc.anl.gov alias is provided as part of LCRC's integration with CELS login infrastructure.</p>"},{"location":"swing/getting-started-swing/#system-architecture","title":"System Architecture","text":"<p>For a detailed overview of the Swing cluster, including the compute node architecture, refer to the Hardware Overview page.</p>"},{"location":"swing/getting-started-swing/#job-execution","title":"Job Execution","text":"<p>For information on how to run jobs on Swing, refer to the Running Jobs page.</p>"},{"location":"swing/hardware-overview-swing/","title":"Swing Hardware Overview","text":"<p>8x NVIDIA A100 GPUS per node 1-2TB DDR4 and 320-640GB GPU memory per node 128 cpu cores per compute node Infiniband HDR Interconnect</p>"},{"location":"swing/hardware-overview-swing/#swing-compute-nodes","title":"Swing Compute Nodes","text":"Swing Compute Description Per Node Aggregate Processor (Note 1) AMD EPYC 7742 2.25GHz 2 Sockets 12 Cores/Threads 64 Cores/2 Threads per core 128/256 768/1,536 Memory DDR4 1 TB (gpu1-4,6)2 TB(gpu5) 7,000 GiB Local SSD 14 TB (gpu1-4,6)28 TB (gpu5) 1 98 TB GPUs NVIDIA A100 80GB (Node gpu5)NVIDIA A100 40GB (Nodes gpu1-4,6) 8 48"},{"location":"swing/hardware-overview-swing/#swing-a100-gpu-information","title":"Swing A100 GPU Information","text":"Description A100-SXM4-80GB A100-SXM4-40GB GPU Memory 80 GiB HBM2 GPU Memory BW 2.4 TB/s Interconnect FP64 9.7 TF FP64 Tensor Core 19.5 TF FP32 19.5 TF BF16 Tensor Core 312 TF FP16 Tensor Core 312 TF INT8 Tensor Core 624 TOPS Max TDP Power 400 W"},{"location":"swing/hardware-overview-swing/#swing-login-nodes","title":"Swing Login Nodes","text":"<p>There are two login nodes available to users for editing code, building code, submitting/monitoring jobs, checking usage (<code>sbank</code>), etc. Their full hostnames are <code>gpulogin1.lcrc.anl.gov</code> and <code>gpulogin2.lcrc.anl.gov</code>.  The login nodes hardware is quite different to the compute nodes. The various compilers and libraries are present on the logins, so most users should be able to build their code. However, software requiring GPUs should be built on the compute nodes as the login nodes do not have GPUs installed in them. All users share the same login nodes so please be courteous and respectful of your fellow users. For example, please do not run computationally or IO intensive pre or post-processing on the logins and keep the parallelism of your builds to a reasonable level.</p>"},{"location":"swing/running-jobs-swing/","title":"Running Jobs on Swing","text":""},{"location":"swing/running-jobs-swing/#quickstart","title":"Quickstart","text":"<p>Presented below are fundamental commands essential for day-to-day use by most LCRC users on Swing. Comprehensive guides are available in other sections linked within our documentation.</p> <p>Check your Current Allocation Balance(s):</p> <pre><code>sbank-list-allocations -p &lt;project_name&gt;\n</code></pre> <p>Check your Filesystem Quota(s):</p> <pre><code>lcrc-quota\n</code></pre> <p>Submit a Batch Job:</p> <pre><code>qsub -A &lt;project&gt; &lt;your job script&gt;\n</code></pre> <p>List All Jobs:</p> <pre><code>qstat\n</code></pre> <p>Delete a Job:</p> <pre><code>qdel &lt;jobid&gt;\n</code></pre>"},{"location":"swing/running-jobs-swing/#job-scheduling-system","title":"Job Scheduling System","text":"<p>Swing's job scheduling system is characterized by:</p> <ul> <li>Uses PBS Pro</li> <li>Uses the <code>sbank</code> accounting system</li> <li>Allocations are calculated in node hours</li> </ul>"},{"location":"swing/running-jobs-swing/#queues","title":"Queues","text":"<p>Swing currently enforces the following limits on publicly available queues:</p> <ul> <li>4 Running Jobs per user.</li> <li>10 Queued Jobs per user.</li> <li>1 Days (24 Hours) Maximum Walltime.</li> <li>1 Hour Default Walltime if not specified.</li> <li>16 GPUs (2 full nodes) Max in use at one time.</li> <li>gpu is the default partition.</li> </ul> <p>Use the -q option with qsub to select a queue.</p> <p>You will be allocated 1/8th of the node resources per GPU. Nodes allow for multiple jobs from multiple users up until the resources are fully consumed (8 jobs with 1 GPU each per node, 1 job with 8 GPU per node, and everything in between).</p> <p>You MUST request at least 1 GPU to run a job. Additionally, you may only request the following number of GPUs per node:</p> <ul> <li>1 GPU</li> <li>2 GPUs</li> <li>4 GPUs</li> <li>8 GPUs</li> </ul> Partition Name Number of Nodes GPUs Per Node GPU Memory Per Node CPUs Per Node DDR4 Memory Per Node Local Scratch Disk Operating System gpu 5 8x NVIDIA A100 40GB 320GB 2x AMD EPYC 7742 64-Core Processor (128 Total Cores) 1TB 14TB Ubuntu 22.04.5 LTS gpu-large 1 8x NVIDIA A100 80GB 640GB 2x AMD EPYC 7742 64-Core Processor (128 Total Cores) 2TB 28TB Ubuntu 22.04.5 LTS backfill 6 8x NVIDIA A100 40GB/80GB 320GB/640GB 2x AMD EPYC 7742 64-Core Processor (128 Total Cores) 1TB/2TB 14TB/28TB Ubuntu 22.04.5 LTS"},{"location":"swing/running-jobs-swing/#backfill-queue","title":"Backfill Queue","text":"<p>The backfill queue is used to improve the overall efficiency of the cluster by utilizing idle resources that would otherwise remain unused. Only jobs that ran out of hours may use the backfill queue, and the maximum wall-time is 4 hours. Users can submit jobs to the backfill queue by specifying it as the target queue in the PBS select statement. For example:</p> <pre><code>#PBS -q backfill\n</code></pre> <p>An example for interactive jobs:</p> <pre><code>qsub -q backfill -l select=1:ngpus=1 -l walltime=15:00 -A support -I\n</code></pre>"},{"location":"swing/running-jobs-swing/#job-submission-examples","title":"Job Submission Examples","text":""},{"location":"swing/running-jobs-swing/#example-qsub-job-submission-script","title":"Example <code>qsub</code> Job Submission Script","text":"<p>Here is an example PBS submission script called <code>gpu-app-script.sh</code> that requests a single GPU for the job.</p> <pre><code>#!/bin/bash -l\n#PBS -N gpu-test\n#PBS -A support\n#PBS -l select=1:ngpus=1\n#PBS -j oe\n#PBS -l walltime=04:00:00\n\ncd $PBS_O_WORKDIR\necho Working directory is $PBS_O_WORKDIR\n\nmodule purge\nmodule load nvhpc\n\nprintf \"CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES\\n\\n\"\n\nnvidia-smi\nexit 0\n</code></pre> <p>You can then submit the script with <code>qsub gpu-app-script.sh</code>.</p>"},{"location":"swing/running-jobs-swing/#example-interactive-job-submission","title":"Example Interactive Job Submission","text":"<p>To run an interactive job in a computing environment using PBS, you can do the following:</p> <pre><code>qsub -I -l select=1:ngpus=1 -l walltime=01:00:00 -q gpu -A &lt;project_name&gt;\n</code></pre> <p>This command requests 1 node and 1 gpu for a period of 1 hour in the gpu queue. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing gpu affinity scripts on the compute node.</p>"},{"location":"using-software/getting-started/","title":"Software","text":""},{"location":"using-software/getting-started/#lmod","title":"Lmod","text":"<p>LCRC uses Lmod (Lua Environment Modules) for software and environment variable management. Lmod has several advantages over other software environments. For example, it prevents you from loading multiple versions of the same package at the same time. It also prevents you from having multiple compilers and MPI libraries loaded at the same time. See the Lmod User Guide for information on how to use Lmod.</p>"},{"location":"using-software/getting-started/#some-basic-commands","title":"Some basic commands","text":""},{"location":"using-software/getting-started/#finding-available-modules","title":"Finding Available Modules","text":"Task Lmod List available modules for the current compiler/MPI library <code>module avail</code> List all available modules <code>module spider</code> List modules with a certain keyword in their description <code>module spider &lt;keyword&gt;</code> List currently loaded modules <code>module list</code>"},{"location":"using-software/getting-started/#loadingunloading-modules","title":"Loading/Unloading Modules","text":"Task Lmod Load a module <code>module load &lt;module_name&gt;</code> Unload a module <code>module unload &lt;module_name&gt;</code> Reload all modules <code>module update</code> Unload all modules <code>module purge</code>"},{"location":"using-software/getting-started/#setting-default-modules","title":"Setting Default Modules","text":"Task Lmod File containing default modules <code>~/.lmod.d/default</code> Save currently loaded modules <code>module save</code> Save currently loaded modules to a new collection <code>module save &lt;filename&gt;</code> Restore previously saved modules <code>module restore</code> Restore previously saved modules from another collection <code>module restore &lt;filename&gt;</code> Return to default modules <code>module reset</code>"},{"location":"using-software/getting-started/#finding-more-information-on-a-module","title":"Finding More Information on a Module","text":"Task Lmod Print info for a module <code>module whatis</code> Print description of a module <code>module help</code> See contents of a module <code>module show &lt;module_name&gt;</code>"},{"location":"using-software/getting-started/#available-software","title":"Available Software","text":"<p>With over 500 active users in fields as diverse as climate modeling, engine simulation, and ab-initio molecular dynamics, LCRC provides a diverse software stack.</p> <p>If you don\u2019t see a software package installed in our environment that you would like to use, please let us know by contacting support@lcrc.anl.gov. We will consider adding software system wide if appropriate for general LCRC use.</p> <p>We generally use a package manager called Spack for most of our software installs, but often need to install packages manually. Keep in mind that the software you want may have dozens of dependencies that also need to be installed, so it may take some time for us to complete the installation for you. Of course, you\u2019re always welcome to install your own software in your home or project directory (if applicable) as well.</p> <p>LCRC does not purchase licenses for users that need paid commercial software. If you need a paid application, please consult with LCRC staff before mkaing a purchase.</p>"},{"location":"using-software/software-specific-guides/How%20to%20run%20VASP6%20efficiently%20on%20Improv/","title":"How to run VASP6 efficiently on Improv","text":"<p>OpenMP can speed up your VASP6 calculations on Improv.</p> <p>The VASP developers state, \"On nodes with many cores, e.g., 64 or more. On such nodes, the memory bandwidth and cache size per core may limit the parallel efficiency of VASP. These problems can be (partly) alleviated by using OpenMP.\" See the VASP manual for details.</p> <p>Zhao et al. found that for many VASP calculations, eight OpenMP threads per MPI process give the best performance on the Zen3 architecture.</p> <p>Improv's AMD EPYC 7713 Zen3 processor has eight core complexes (CCXs).  Each CCX has eight cores sharing a common L3 memory cache. VASP6 can exploit the fast bandwidth of these caches with openMP.  We have tested the effect of using VASP configured to use openMP on the elapsed time for a single gamma point calculation for a ferromagnetic Pt296Fe255 cluster with VASP v6.5.1 on eight Improv nodes (1024 cores).  The results are presented in the figure below.</p> <p></p> <p>Note that using four, eight, or sixteen OpenMP threads per MPI process is more than twice as fast as pure MPI (1 OpenMP thread per MPI process) for this benchmark. VASP with eight OpenMP threads per MPI process is the fastest (2.7 times faster than one OpenMP thread per MPI process). We recommend testing the effect of the number of OpenMP threads on your calculations because the speedup with threads may be different for your calculations. </p> <p>Sample scripts to run VASP 6.5.1 and VASP 6.4.3 with eight OpenMP threads on Improv can be found at /software/software/custom-built/vasp/6.5.1/mt/example and /software/software/custom-built/vasp/6.4.3/mt/example.</p>"},{"location":"using-software/software-specific-guides/conda/","title":"Using Conda in LCRC","text":"<p>Due to a change in licensing requirements, we will no longer provide modules or support for Anaconda. Instead, we provide Miniforge, which is a repository that holds the minimal installers for Conda and Mamba specific to conda-forge.</p> <p>Conda modules that we provide include a common set of packages: pip, numpy, scipy, matplotlib, mpi4py, etc</p> <p>If the Miniforge module does not have python package that you need already installed, you can create an Conda environment inside your home directory and install the needed packages there.</p> <p>First, load the Miniforge module that you need:</p> <pre><code>module load miniforge3/&lt;version&gt;\n</code></pre> <p>Now you can list the already installed packages by running:</p> <pre><code>conda list\n</code></pre> <p>If your package is not installed, you can search to see if it exists to install by running:</p> <pre><code>conda search &lt;package_name&gt;\n</code></pre> <p>If your package is not installed and appears in the available package list, you can create a new conda environment to install the package in. The following command will create an Conda environment in your home directory:</p> <pre><code>conda create -n &lt;environment_name&gt;\n</code></pre> <p>To activate that environment, run:</p> <pre><code>source activate &lt;environment_name&gt;\n</code></pre> <p>Now you are ready to install the package:</p> <pre><code>conda install &lt;package_name&gt;\n</code></pre> <p>The complete instructions on how to use Conda are at: https://conda.io/docs/index.html</p> <p>If the packages are not provided with pip or Conda and the procedure for installation is very complex, feel free to email to support@lcrc.anl.gov.</p>"},{"location":"using-software/software-specific-guides/gaussian/","title":"Gaussian","text":"<p>Gaussian uses Linda rather than MPI to communicate between nodes. You need to pass directives to Gaussian to specify which nodes to use and how many processes to use on each node.  The simplest way to do this is to start a Linda worker on each node and spawn a number of threads equal to the number of cores on the node. </p>"},{"location":"using-software/software-specific-guides/gaussian/#using-gaussian-on-improv","title":"Using Gaussian on Improv","text":"<p>Gaussian can be loaded and unloaded with the following commands respectively (for these examples, I'm using <code>gaussian/16.C.02</code>):</p> <pre><code>module load gaussian/16.C.02\nmodule unload gaussian/16.C.02\n</code></pre> <p>It is extremely important that you define the environmental variable GAUSS_SCRDIR to be the local disk on the compute node (/scratch).  Otherwise, Gaussian will use the working directory on a shared file system as scratch space. This can slow down the LCRC servers.</p> <p>Below are sample PBS script that can be used to run Gaussian on Improv node(s) with optimal performance. The first example will run on 2 nodes for larger calculations that can scale to a full node of Improv.</p> <pre><code>#!/bin/bash\n#PBS -N &lt;JOB_NAME&gt;\n#PBS -l select=2:ncpus=128:mpiprocs=1:ompthreads=128\n#PBS -A &lt;PROJECT_ALLOCATION&gt;\n#PBS -l walltime=02:00:00\n\nmodule load gaussian/16.C.02\n\ncd $PBS_O_WORKDIR\nnp=`wc -l &lt; $PBS_NODEFILE`\nnn=`sort -u $PBS_NODEFILE | wc -l`\nnode_list=`sort -u $PBS_NODEFILE| paste -d, -s`\n\necho \" np= \" $np\necho \" nn= \" $nn\necho \" node_list= \" $node_list\n\nexport GAUSS_CDEF=0-127\nexport GAUSS_MDEF=200GB\nexport GAUSS_WDEF=$node_list\nexport GAUSS_SCRDIR=/scratch/test\nmkdir $GAUSS_SCRDIR\nexport GAUSS_SDEF=ssh\nexport GAUSS_LFLAGS=\"-vv\"\ng16 Grubbs2\nrm -rf $GAUSS_SCRDIR\n</code></pre> <p>The next example will pack 4 Gaussian jobs onto 1 node to utilize all 128 cores when the calculation does not scale as well. We do this to not waste cores that would otherwise sit idle.</p> <p>The PBS directive <code>-l select=1:ncpus=128:mpiprocs=4:ompthreads=32</code> requests a single node (<code>select=1</code>) with 128 CPUs, where 4 MPI processes (<code>mpiprocs=4</code>) are to be launched. Each MPI process is configured to use 32 OpenMP threads (<code>ompthreads=32</code>).</p> <pre><code>#!/bin/bash\n\n#PBS -N &lt;JOB_NAME&gt;\n#PBS -l select=1:ncpus=128:mpiprocs=4:ompthreads=32\n#PBS -A &lt;PROJECT_ALLOCATION&gt;\n#PBS -l walltime=02:00:00\n\nmodule load gaussian/16.C.02\n\n#This script will run four gaussian jobs\n#on 32 cores of improv simulataneously\n\n#Note that each calculation runs in a unique subfolder\n#and has a unique scratch disk.\n\ncd $PBS_O_WORKDIR\n\nfor ii in 0 1 2 3; do\n    let jj=ii*32\n    let kk=jj+31\n    let ll=ii+1\n        export GAUSS_CDEF=$jj-$kk\n        export GAUSS_MDEF=200GB\n        export GAUSS_SCRDIR=/scratch/$PBS_JOBID/$ll\n        mkdir -p $GAUSS_SCRDIR\n    cd test$ll\n        (g16 test_$ll\n    rm -rf $GAUSS_SCRDIR)&amp;\n    cd ..\ndone\nwait\n</code></pre>"},{"location":"using-software/software-specific-guides/jupyter-notebooks/","title":"Using Jupyter Notebooks in LCRC","text":"<p>Here, we will outline how to use Jupyter Notebooks in LCRC from a local machine running Linux/MacOS. Below are examples that can be done on any LCRC cluster. Jupyter Notebooks should not be launched on any of the login nodes, but instead be run from an interactive compute node.</p> <p>In this full example, commands are shown for the Improv cluster on ilogin1 (login node) and i001 (compute node), but should be changed appropriately based on the cluster and nodes you actually land on.</p> <p>First, login to Improv for this example:</p> <pre><code>ssh &lt;username&gt;@improv.lcrc.anl.gov\n</code></pre> <p>Now we will activate a more recent version of conda for python3:</p> <pre><code>/soft/software/custom-built/anaconda3/2023.09/bin/conda init bash\n</code></pre> <p>You may see a lot of output here, but it will instruct you to reload your shell. For changes to take effect, close and re-open your current shell, preferably by logging out and back in.</p> <p>Once you log back in, you should verify you have the correct conda environment loaded:</p> <pre><code>conda --version\n</code></pre> <p>This should output: <code>conda 23.7.4</code></p> <p>If you see the version above (or the one you expect), you can move on to the next step.</p> <p>Start an interactive job. We have used the Improv debug queue in this example, since these nodes are always available for short testing/debugging jobs. Remember to replace PROJECT_NAME with a valid project you belong to. </p> <pre><code>qsub -I -A PROJECT_NAME -l select=1:ncpus=128:mpiprocs=128,walltime=01:00:00 -q debug\n</code></pre> <p>This command will drop you into 1 random debug node for 1 hour \u2013 in this example we will show it as i001.</p> <p>On the compute node i001, type:</p> <pre><code>conda activate\n</code></pre> <p>This will give you access to the newer conda environment now.</p> <p>Now run:</p> <pre><code>which jupyter\n</code></pre> <p>You should see: <code>/soft/software/custom-built/anaconda3/2023.09/bin/jupyter</code></p> <p>confirming you have the right Jupyter executable loaded.</p> <p>Now, launch Jupyter Notebook on the compute node (again, i001 in our case):</p> <pre><code>jupyter notebook --no-browser\n</code></pre> <p>After several seconds, you should see something like:</p> <pre><code>[I 14:00:16.503 NotebookApp] Jupyter Notebook 6.5.4 is running at:\n[I 14:00:16.503 NotebookApp] http://localhost:8888/?token=3ghbn74a98fbcf4235342d7a835a6d3b5e9d19934be3786e\n[I 14:00:16.503 NotebookApp]  or http://127.0.0.1:8888/?token=3ghbn74a98fbcf4235342d7a835a6d3b5e9d19934be3786e\n[I 14:00:16.503 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[C 14:00:16.508 NotebookApp]\n\n    To access the notebook, open this file in a browser:\n        file:///gpfs/fs1/home/username/.local/share/jupyter/runtime/nbserver-2561216-open.html\n    Or copy and paste one of these URLs:\n        http://localhost:8888/?token=3ghbn74a98fbcf4235342d7a835a6d3b5e9d19934be3786e\n     or http://127.0.0.1:8888/?token=3ghbn74a98fbcf4235342d7a835a6d3b5e9d19934be3786e\n</code></pre> <p>Please make a note of the provided URL at the bottom of the output (make sure to use your output and not the example text above). You will need that later. Also, please note that the port number after localhost may be different. In this example, it is 8888. You should change the below commands to match this port where necessary.</p> <p>From another terminal on your local machine, run:</p> <pre><code>ssh -L 8888:localhost:8888 &lt;username&gt;@ilogin1.lcrc.anl.gov\n</code></pre> <p>This will open a new, port forwarded session on ilogin1. You may encounter a scenario where the default port of 8888 is already in use and see something like:</p> <pre><code>bind [127.0.0.1]:8888: Address already in use\nchannel_setup_fwd_listener_tcpip: cannot listen to port: 8888\nCould not request local forwarding. \n</code></pre> <p>If this happens, you may want to change the port altogether. You can change it by adding the following to your Jupyter Notebook command from earlier. Simply cancel the process and restart the process with:</p> <pre><code>jupyter notebook --port=&lt;port number&gt; --no-browser\n</code></pre> <p>We recommend you simply increase the port number by one to the next value from the default. For example, 8889 or 8890 if others are in use.</p> <p>Now, from this new session on ilogin1, SSH into the compute node running your Jupyter Notebook command from earlier:</p> <pre><code>ssh -L 8888:localhost:8888 i001\n</code></pre> <p>Finally, cut-paste the URL obtained by launching Jupyter Notebook on the compute node earlier into a browser (Firefox/Chrome for example) running on your local machine.</p> <p>This should launch the Jupyter Notebook on the browser of your local machine.</p>"},{"location":"using-software/software-specific-guides/openmc/","title":"OpenMC","text":"<p>OpenMC uses both distributed-memory (MPI) and shared-memory (OpenMP) parallelism to maximize computational efficiency. Optimal performance is achieved by aligning parallelization strategies with hardware architecture, such as using one MPI process per NUMA node on servers with large core counts or employing hardware threading.</p>"},{"location":"using-software/software-specific-guides/openmc/#using-openmc-on-improv","title":"Using OpenMC on Improv","text":"<p>On Improv, OpenMC was installed in a Conda environment. The envionment can be loaded and unloaded with the following commands respectively (for these examples, I'm using <code>openmc/0.14.0</code>):</p> <pre><code>module load openmc/0.14.0\nmodule unload openmc/0.14.0\n</code></pre> <p>Below is a sample PBS script that can be used to run OpenMC on an Improv node with optimal performance.</p> <ul> <li>The PBS directive <code>-l select=1:ncpus=128:mpiprocs=8:ompthreads=16</code> requests a single node (<code>select=1</code>) with 128 CPUs, where 8 MPI processes (<code>mpiprocs=8</code>) are to be launched. Each MPI process is configured to use 16 OpenMP threads (<code>ompthreads=16</code>).</li> <li>When the script executes the <code>mpiexec</code> command, it launches 8 separate MPI processes (<code>-np 8</code>). The <code>--bind-to numa</code> and <code>--map-by numa</code> options instruct OpenMPI to bind each process to a NUMA node and map the processes by NUMA node.</li> </ul> <pre><code>#!/bin/bash\n\n#PBS -N &lt;JOB_NAME&gt;\n#PBS -l select=1:ncpus=128:mpiprocs=8:ompthreads=16\n#PBS -l walltime=6:00:00\n#PBS -j oe\n#PBS -A &lt;PROJECT_ALLOCATION&gt;\n#PBS -o output_&lt;JOB_NAME&gt;\n#PBS -e error_&lt;JOB_NAME&gt;\n\nmodule load openmc/0.14.0\n\n# Set the necessary OpenMC variables and paths. For example:\nexport OPENMC_CROSS_SECTIONS=&lt;PATH_TO_CROSS_SECTIONS&gt;\nexport OPENMC_DEPLETE_CHAIN=&lt;PATH_TO_DEPLETE_CHAIN&gt;\n\n# Set the number of OpenMP threads\nexport OMP_NUM_THREADS=16\n\n# Change to the directory from which the job was submitted\ncd $PBS_O_WORKDIR\n\n# Launch mpiexec with proper NUMA binding and process mapping. Replace the python script name with your script.\nmpiexec -np 8 --bind-to numa --map-by numa python &lt;YOUR_SCRIPT_NAME&gt;.py\n</code></pre>"},{"location":"using-software/software-specific-guides/paraview/","title":"Using Paraview in LCRC","text":"<p>Here, we will outline how to use Paraview in client-server mode in LCRC from a local machine running Linux/MacOS. Below are examples using the Bebop cluster. Paraview itself should not be launched on any of the login nodes, but instead be run in client-server mode.</p>"},{"location":"using-software/software-specific-guides/paraview/#paraview-client-server-to-an-lcrc-login-node","title":"Paraview Client-Server to an LCRC Login Node","text":"<p>In this first example, commands are shown for beboplogin3 and should be changed appropriately if you are using another login node.</p> <p>First, login to Bebop for this example:</p> <pre><code>ssh &lt;username&gt;@bebop.lcrc.anl.gov\n</code></pre> <p>Make note of the login node name and number that you end up on. As mentioned for this example, it is beboplogin3, but may be different for you.</p> <p>Now, load the Paraview module (in this example we are using paraview 5.4.0. Users can check the available versions of paraview by using the command <code>module spider paraview</code>. Load any of the modules of paraview available and ensure that you have the same version available on your local machine.):</p> <pre><code>module load paraview/5.4.0\n</code></pre> <p>You can verify that Paraview is loaded if you can produce this output:</p> <pre><code>$ which pvserver\n/soft/bebop/paraview/5.4.0/bin/pvserver\n</code></pre> <p>Launch pvserver in your case directory:</p> <pre><code>pvserver\n</code></pre> <p>You should get output similar to the following:</p> <pre><code>Waiting for client...\nConnection URL: cs://beboplogin3:11111\nAccepting connection(s): beboplogin3:11111\n</code></pre> <p>Now, open new terminal on your local machine/desktop (Mac/Linux). Create an SSH tunnel to the login node you started pvserver on:</p> <pre><code>ssh -L 11111:localhost:11111 &lt;username&gt;@beboplogin3.lcrc.anl.gov\n</code></pre> <p>Back on your local machine, download and install the Linux/MacOS Paraview version 5.4.0 (or the matching version from the Paraview module you loaded in the first step) from the Paraview website.</p> <p>Once installed, launch Paraview locally and set up the connection to connect to our server instance.</p> <p>Click on the icon for Connect (marked in red circle on the figure below) and then click on the Add Server tab: </p> <p>Fill in the details as shown below. You should use the port number given to you from when you started the pvserver instance if different than below. Set the name as one of the login nodes, beboplogin2, beboplogin3, etc. and hit Configure: </p> <p>This will take you to the next tab where you can hit Save to save the configuration (Startup Type is Manual which is the default setting): </p> <p>After adding a server, you should see a panel as shown below. You could add multiple servers using the above procedure. Click on the server name where you have started pvserver (in this example it would be beboplogin3) and hit Connect: </p> <p>To verify your connection was successful (aside from no error messages locally), you should now see a connection message on the window running pvserver (note the last line below):</p> <pre><code>Waiting for client...\nConnection URL: cs://beboplogin3:11111\nAccepting connection(s): beboplogin3:11111\nClient connected.\n</code></pre> <p>Once connected, you should be able to open your solution files in your case directory on Bebop (since pvserver was launched from it). Open a case file clicking on the icon marked in the red circle below: </p> <p>Your solution files should now be running in client-server mode.</p>"},{"location":"using-software/software-specific-guides/paraview/#paraview-client-server-to-an-lcrc-compute-node-gpu-example","title":"Paraview Client-Server to an LCRC Compute Node (GPU Example)","text":"<p>Users who need to visualize large problems will have to use a compute node with more resources, preferably on a GPU resource. The below is an example of how to do this on the LCRC Swing cluster.</p> <p>Note: If needed, please reference the first section of this page for any screenshots needed if you have trouble finding an option in the Paraview GUI.</p> <p>First, login to Swing for this example:</p> <pre><code>ssh &lt;username&gt;@swing.lcrc.anl.gov\n</code></pre> <p>Make note of the login node name and number that you end up on.</p> <p>Request an interactive job on 1 node and 1 GPU (for 30 minutes as an example):</p> <pre><code>qsub -I -l select=1:ngpus=1 -l walltime=00:30:00 -q gpu -A &lt;project_name&gt;\n</code></pre> <p>Note: The partition may not have free nodes so you might not be able to start your interactive job immediately.</p> <p>You will automatically SSH into the node allocated to your job (say gpu1 for example).</p> <p>Now, load the Paraview module:</p> <pre><code>module load paraview/5.11.1\n</code></pre> <p>You can verify that Paraview is loaded if you can produce this output:</p> <pre><code>$ which pvserver\n/gpfs/fs1/soft/swing/manual/paraview/5.11.1/bin/pvserver\n</code></pre> <p>Launch pvserver in your case directory:</p> <pre><code>pvserver --server-port=11111\n</code></pre> <p>You should get output similar to the following:</p> <pre><code>Waiting for client...\nConnection URL: cs://&lt;node_number&gt;:11111\nAccepting connection(s): &lt;node_number&gt;:11111\n</code></pre> <p>From your local Linux/MacOS machine type the following command to set up the tunnel to the allotted node:</p> <pre><code>ssh -L 11111:&lt;node_number&gt;.lcrc.anl.gov:11111 &lt;username&gt;@gpulogin&lt;node_number&gt;.lcrc.anl.gov\n</code></pre> <p>For example, if you have logged onto gpulogin1 to launch your interactive job and your allotted node number is gpu1 then your command will be:</p> <pre><code>ssh -L 11111:gpu1.lcrc.anl.gov:11111 &lt;username&gt;@gpulogin1.lcrc.anl.gov\n</code></pre> <p>Launch Paraview from your local machine and connect to the gpulogin node (gpulogin1 in the above example) as explained in the first section of this page.</p> <p>On the node you should see:</p> <pre><code>Waiting for client...\nConnection URL: cs://&lt;node_number&gt;:11111\nAccepting connection(s): &lt;node_number&gt;:11111\nClient connected.\n</code></pre> <p>You can now navigate to the case folder and load the case as described above. After viewing your case, you can cancel the interactive job by either exiting completely out of your node session.</p>"},{"location":"using-software/software-specific-guides/tensorflow/","title":"Using Tensorflow in LCRC","text":"<p>To use TensorFlow on the LCRC GPU resources, we recommend using a container. In LCRC, we support Singularity for containers. Below, we\u2019ll highlight how to get a container, load Singularity to build your container and run a simple test. Before proceeding, you should be familiar with how to run an interactive job on Swing.</p>"},{"location":"using-software/software-specific-guides/tensorflow/#getting-the-container","title":"Getting the Container","text":"<p>To get a suitable container which has the latest CUDA and TensorFlow installed, head over to the NVIDIA NGC website and search for Tensorflow. Click on the TensorFlow link.</p> <p>You should now see some basic information about TensorFlow. At the top of the page, you\u2019ll notice versions next to \u2018Pull Tag\u2018. Also notice there are containers tagged with tf1 and tf2. Make sure to select the correct version that applies to you. Choose the correct version and click 'Pull Tag'. This will copy a Docker URL to your clipboard. More on this later. For this example, we\u2019ll use version 21.12-tf2-py3.</p>"},{"location":"using-software/software-specific-guides/tensorflow/#building-your-container","title":"Building your Container","text":"<p>Next, from a Swing login node for example, start an interactive job. In this example, we\u2019ll request 2 GPUs.</p> <pre><code>gpulogin1:~$ qsub -I -l select=1:ngpus=2 -A &lt;project_name&gt;\n\n</code></pre> <p>Once your job starts, you should be put onto your allocated node. Node gpu6 in this example. Now we can load the Singularity module:</p> <pre><code>gpu6:~$ module load singularity\n</code></pre> <p>Using the Tag you copied in the previous section, let\u2019s build a container with Singularity. Because these are actually Docker built containers by default, what we are doing is converting them to a Singularity ready container. The Tag you copied will probably look like this: <code>docker pull nvcr.io/nvidia/tensorflow:21.12-tf2-py3</code>.</p> <p>Let\u2019s use what we need below to convert this now:</p> <pre><code>gpu6:~$ singularity build tensorflow-21.12-tf2-py3.simg docker://nvcr.io/nvidia/tensorflow:21.12-tf2-py3\n</code></pre> <p>tensorflow-21.12-tf2-py3.simg is the name of your new container. You can name this whatever you\u2019d like, but we\u2019ll keep the naming consistent. The above command may take several minutes.</p>"},{"location":"using-software/software-specific-guides/tensorflow/#testing-tensorflow","title":"Testing TensorFlow","text":"<p>Lastly, we\u2019ll test that the TensorFlow container works. We\u2019ll do a simple query of the GPUs we allocated earlier. Remember, we only requested 2 GPUs:</p> <pre><code>gpu6:~$ singularity exec --nv tensorflow-21.12-tf2-py3.simg python -c \"import tensorflow as tf; tf.test.gpu_device_name()\"\n\n2022-01-05 15:20:08.205124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 38188 MB memory:  -&gt; device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n\n2022-01-05 15:20:08.230207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:1 with 38188 MB memory:  -&gt; device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:4e:00.0, compute capability: 8.0\n</code></pre> <p>When you are finished testing, remember to relinquish your node allocation. For more information, including tutorials, please review the TensorFlow documentation on the NVIDIA website and well as the Singularity user guide.</p>"},{"location":"using-software/software-specific-guides/vasp/","title":"VASP","text":""},{"location":"using-software/software-specific-guides/vasp/#using-vasp-on-improv","title":"Using VASP on Improv","text":"<p>VASP can be loaded and unloaded with the following commands respectively (for these examples, I'm using <code>vasp/6.4.3</code>):</p> <pre><code>module load vasp/6.4.3\nmodule unload vasp/6.4.3\n</code></pre> <p>An example script to run VASP on Improv can be found at /soft/software/custom-built/vasp/6.4.3/st/example/vasp.pbs.</p> <p>An example script to run VASP on Bebop can be found at /soft/software/custom-built/vasp/6.4.3_st/example/vasp.pbs.</p> <p>The parallel performance of VASP can be optimized with a few INCAR tags.</p> <p>We recommend using NCORE and KPAR in your INCAR file on Improv to improve parallel performance.</p> <p>NCORE should be set to a divisor of 16 on Improv.  We find that NCORE=8 gives good parallel performance on Improv. To get the optimal performance on Improv, you should test NCORE=2, 4, 8, and 16 for your case.</p> <p>NCORE should be set to a divisor of 18 on Bebop.  We find that NCORE=6 gives good parallel performance on Bebop. To get the optimal performance on Bebop, you should test NCORE=2, 3, 6, 9, and 18 for your case.</p> <p>Using NCORE=1 is discouraged except for GW and RPA calculations.</p> <p>KPAR should be set to a divisor of the number of k-points.                       Setting KPAR to the number of nodes being used will give the most improvement in parallel performance.</p> <p>NCORE*KPAR must be a divisor of the number of cores being used.</p> <p>See the VASP wiki at https://www.vasp.at/wiki/index.php/Category:Parallelization for more details.</p> <p>Unfortunately, the parallel performance of VASP will be poor when using more cores than atoms. For calculations involving multiple k-points, the KPAR tag will improve parallel scaling for small cells.</p> <p>To improve the efficiency of small VASP calculations, you can run several VASP calculations in parallel in a single batch job.  An example script to do this can be found at /soft/software/custom-built/vasp/6.4.2/example/multiple-mpi/test.sh on Improv.</p> <p>``` You can improve the performance of VASP6 on Improv by using the hybrid MPI/OpenMP build of VASP6; see this link for details.</p>"}]}